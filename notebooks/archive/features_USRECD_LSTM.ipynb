{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import figure\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import TimeSeriesSplit, train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "References:\n",
    "1. https://machinelearningmastery.com/how-to-develop-lstm-models-for-time-series-forecasting/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Settings:\n",
    "pd.set_option('display.width', 190)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 20)\n",
    "pd.set_option('max_colwidth', 200)\n",
    "pd.options.display.float_format = '{:.4f}'.format\n",
    "plt.style.use('default')\n",
    "np.set_printoptions(threshold = 30, edgeitems = 30, precision = 2, suppress = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_sequences(Xs, ys, n_steps):\n",
    "    X, y = list(), list()\n",
    "    for i in range(len(ys)):\n",
    "        # find the end of this pattern\n",
    "        end_ix = i + n_steps\n",
    "        # check if we are beyond the dataset\n",
    "        if end_ix > len(ys):\n",
    "            break\n",
    "        # gather input and output parts of the pattern\n",
    "        seq_x, seq_y = Xs[i: end_ix], ys[end_ix - 1]\n",
    "        X.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "    return np.array(X), np.array(y).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam\n",
    "from skorch import NeuralNetBinaryClassifier\n",
    "\n",
    "\n",
    "class MyModule(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyModule, self).__init__()\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size=20, hidden_size=10, num_layers=1, batch_first=True)\n",
    "        self.dense = nn.Linear(10, 1)\n",
    "\n",
    "    def forward(self, X, **kwargs):\n",
    "        output, hidden = self.lstm(X)\n",
    "        X = self.dense(output[:, -1, :])\n",
    "        return X\n",
    "\n",
    "def get_model():\n",
    "    model = NeuralNetBinaryClassifier(\n",
    "        MyModule,\n",
    "        optimizer=Adam,\n",
    "        max_epochs=50,\n",
    "        lr=3e-4,\n",
    "        batch_size=16,\n",
    "        iterator_train__shuffle=True,\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_path = \"../merged_data/features_USRECD.csv\"\n",
    "features = [\"BCI\", \"BCIp\", \"BCIg\", 'IE_SP_Comp', 'IE_SP_Dividend', 'IE_SP_Earnings', 'IE_Consumer_CPI', 'IE_Long_Interest', 'IE_Real_Price', 'IE_Real_Dividend', 'IE_Return_Price', 'IE_Real_Earnings',\n",
    "                'IE_Scaled_Earnings', 'IE_Monthly_Returns', 'IE_Real_Returns', \"YC_10_Year\", \"YC_3_Month\", \"YC_3_Month_Bond\", \"YC_Spread\", \"YC_Rec_Prob\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BCI</th>\n",
       "      <th>BCIp</th>\n",
       "      <th>BCIg</th>\n",
       "      <th>USRECD</th>\n",
       "      <th>IE_SP_Comp</th>\n",
       "      <th>IE_SP_Dividend</th>\n",
       "      <th>IE_SP_Earnings</th>\n",
       "      <th>IE_Consumer_CPI</th>\n",
       "      <th>IE_Long_Interest</th>\n",
       "      <th>IE_Real_Price</th>\n",
       "      <th>IE_Real_Dividend</th>\n",
       "      <th>IE_Return_Price</th>\n",
       "      <th>IE_Real_Earnings</th>\n",
       "      <th>IE_Scaled_Earnings</th>\n",
       "      <th>IE_Monthly_Returns</th>\n",
       "      <th>IE_Real_Returns</th>\n",
       "      <th>YC_10_Year</th>\n",
       "      <th>YC_3_Month</th>\n",
       "      <th>YC_3_Month_Bond</th>\n",
       "      <th>YC_Spread</th>\n",
       "      <th>YC_Rec_Prob</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1967-02-09</th>\n",
       "      <td>4.6052</td>\n",
       "      <td>6.5870</td>\n",
       "      <td>3.4751</td>\n",
       "      <td>0</td>\n",
       "      <td>4.4362</td>\n",
       "      <td>1.0578</td>\n",
       "      <td>1.7084</td>\n",
       "      <td>3.4935</td>\n",
       "      <td>1.5217</td>\n",
       "      <td>6.5522</td>\n",
       "      <td>3.1739</td>\n",
       "      <td>11.4502</td>\n",
       "      <td>3.8238</td>\n",
       "      <td>8.7218</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>2.5153</td>\n",
       "      <td>1.5217</td>\n",
       "      <td>1.5518</td>\n",
       "      <td>1.5776</td>\n",
       "      <td>1.2065</td>\n",
       "      <td>-1.1432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1967-02-16</th>\n",
       "      <td>4.6052</td>\n",
       "      <td>6.5863</td>\n",
       "      <td>3.4751</td>\n",
       "      <td>0</td>\n",
       "      <td>4.4362</td>\n",
       "      <td>1.0578</td>\n",
       "      <td>1.7084</td>\n",
       "      <td>3.4935</td>\n",
       "      <td>1.5217</td>\n",
       "      <td>6.5522</td>\n",
       "      <td>3.1739</td>\n",
       "      <td>11.4502</td>\n",
       "      <td>3.8238</td>\n",
       "      <td>8.7218</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>2.5153</td>\n",
       "      <td>1.5217</td>\n",
       "      <td>1.5518</td>\n",
       "      <td>1.5776</td>\n",
       "      <td>1.2065</td>\n",
       "      <td>-1.1432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1967-02-23</th>\n",
       "      <td>4.6012</td>\n",
       "      <td>6.5774</td>\n",
       "      <td>3.4751</td>\n",
       "      <td>0</td>\n",
       "      <td>4.4362</td>\n",
       "      <td>1.0578</td>\n",
       "      <td>1.7084</td>\n",
       "      <td>3.4935</td>\n",
       "      <td>1.5217</td>\n",
       "      <td>6.5522</td>\n",
       "      <td>3.1739</td>\n",
       "      <td>11.4502</td>\n",
       "      <td>3.8238</td>\n",
       "      <td>8.7218</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>2.5153</td>\n",
       "      <td>1.5217</td>\n",
       "      <td>1.5518</td>\n",
       "      <td>1.5776</td>\n",
       "      <td>1.2065</td>\n",
       "      <td>-1.1432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1967-03-02</th>\n",
       "      <td>4.6032</td>\n",
       "      <td>6.5820</td>\n",
       "      <td>3.4751</td>\n",
       "      <td>0</td>\n",
       "      <td>4.4700</td>\n",
       "      <td>1.0613</td>\n",
       "      <td>1.7011</td>\n",
       "      <td>3.4935</td>\n",
       "      <td>1.5326</td>\n",
       "      <td>6.5860</td>\n",
       "      <td>3.1772</td>\n",
       "      <td>11.4869</td>\n",
       "      <td>3.8177</td>\n",
       "      <td>8.7185</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>2.5153</td>\n",
       "      <td>1.5326</td>\n",
       "      <td>1.5173</td>\n",
       "      <td>1.5427</td>\n",
       "      <td>1.2692</td>\n",
       "      <td>-1.2586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1967-03-09</th>\n",
       "      <td>4.6042</td>\n",
       "      <td>6.5852</td>\n",
       "      <td>3.4751</td>\n",
       "      <td>0</td>\n",
       "      <td>4.4700</td>\n",
       "      <td>1.0613</td>\n",
       "      <td>1.7011</td>\n",
       "      <td>3.4935</td>\n",
       "      <td>1.5326</td>\n",
       "      <td>6.5860</td>\n",
       "      <td>3.1772</td>\n",
       "      <td>11.4869</td>\n",
       "      <td>3.8177</td>\n",
       "      <td>8.7185</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>2.5153</td>\n",
       "      <td>1.5326</td>\n",
       "      <td>1.5173</td>\n",
       "      <td>1.5427</td>\n",
       "      <td>1.2692</td>\n",
       "      <td>-1.2586</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              BCI   BCIp   BCIg  USRECD  IE_SP_Comp  IE_SP_Dividend  IE_SP_Earnings  IE_Consumer_CPI  IE_Long_Interest  IE_Real_Price  IE_Real_Dividend  IE_Return_Price  IE_Real_Earnings  \\\n",
       "Date                                                                                                                                                                                         \n",
       "1967-02-09 4.6052 6.5870 3.4751       0      4.4362          1.0578          1.7084           3.4935            1.5217         6.5522            3.1739          11.4502            3.8238   \n",
       "1967-02-16 4.6052 6.5863 3.4751       0      4.4362          1.0578          1.7084           3.4935            1.5217         6.5522            3.1739          11.4502            3.8238   \n",
       "1967-02-23 4.6012 6.5774 3.4751       0      4.4362          1.0578          1.7084           3.4935            1.5217         6.5522            3.1739          11.4502            3.8238   \n",
       "1967-03-02 4.6032 6.5820 3.4751       0      4.4700          1.0613          1.7011           3.4935            1.5326         6.5860            3.1772          11.4869            3.8177   \n",
       "1967-03-09 4.6042 6.5852 3.4751       0      4.4700          1.0613          1.7011           3.4935            1.5326         6.5860            3.1772          11.4869            3.8177   \n",
       "\n",
       "            IE_Scaled_Earnings  IE_Monthly_Returns  IE_Real_Returns  YC_10_Year  YC_3_Month  YC_3_Month_Bond  YC_Spread  YC_Rec_Prob  \n",
       "Date                                                                                                                                  \n",
       "1967-02-09              8.7218              0.0000           2.5153      1.5217      1.5518           1.5776     1.2065      -1.1432  \n",
       "1967-02-16              8.7218              0.0000           2.5153      1.5217      1.5518           1.5776     1.2065      -1.1432  \n",
       "1967-02-23              8.7218              0.0000           2.5153      1.5217      1.5518           1.5776     1.2065      -1.1432  \n",
       "1967-03-02              8.7185              0.0100           2.5153      1.5326      1.5173           1.5427     1.2692      -1.2586  \n",
       "1967-03-09              8.7185              0.0100           2.5153      1.5326      1.5173           1.5427     1.2692      -1.2586  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the data and do a little bit of wrangling:\n",
    "df = pd.read_csv(df_path)\n",
    "df.Date = pd.to_datetime(df.Date)\n",
    "df = df.set_index(\"Date\", drop=True)\n",
    "df = df.drop(columns=\"Unnamed: 0\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into training and test sets and hold out the test set until the end, so that it remains \"unseen\".\n",
    "lag_of_y = 21 # This is the lag we introduce to the target variable so that we assess the indicator's \n",
    "              # ability to predict the target variable this many steps into the future.\n",
    "              # With BCI, a lag of 21 data points corresponds to about half a year.\n",
    "        \n",
    "X_train, X_test, y_train, y_test = train_test_split(df.iloc[:-lag_of_y, df.columns != \"USRECD\"], \\\n",
    "    df.iloc[lag_of_y:, df.columns == \"USRECD\"], test_size=0.1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29 ... 471 472 473 474 475\n",
      " 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493\n",
      " 494 495 496 497 498 499 500] TEST: [ 501  502  503  504  505  506  507  508  509  510  511  512  513  514\n",
      "  515  516  517  518  519  520  521  522  523  524  525  526  527  528\n",
      "  529  530 ...  971  972  973  974  975  976  977  978  979  980  981  982\n",
      "  983  984  985  986  987  988  989  990  991  992  993  994  995  996\n",
      "  997  998  999 1000]\n",
      "TRAIN: [   0    1    2    3    4    5    6    7    8    9   10   11   12   13\n",
      "   14   15   16   17   18   19   20   21   22   23   24   25   26   27\n",
      "   28   29 ...  971  972  973  974  975  976  977  978  979  980  981  982\n",
      "  983  984  985  986  987  988  989  990  991  992  993  994  995  996\n",
      "  997  998  999 1000] TEST: [1001 1002 1003 1004 1005 1006 1007 1008 1009 1010 1011 1012 1013 1014\n",
      " 1015 1016 1017 1018 1019 1020 1021 1022 1023 1024 1025 1026 1027 1028\n",
      " 1029 1030 ... 1471 1472 1473 1474 1475 1476 1477 1478 1479 1480 1481 1482\n",
      " 1483 1484 1485 1486 1487 1488 1489 1490 1491 1492 1493 1494 1495 1496\n",
      " 1497 1498 1499 1500]\n",
      "TRAIN: [   0    1    2    3    4    5    6    7    8    9   10   11   12   13\n",
      "   14   15   16   17   18   19   20   21   22   23   24   25   26   27\n",
      "   28   29 ... 1471 1472 1473 1474 1475 1476 1477 1478 1479 1480 1481 1482\n",
      " 1483 1484 1485 1486 1487 1488 1489 1490 1491 1492 1493 1494 1495 1496\n",
      " 1497 1498 1499 1500] TEST: [1501 1502 1503 1504 1505 1506 1507 1508 1509 1510 1511 1512 1513 1514\n",
      " 1515 1516 1517 1518 1519 1520 1521 1522 1523 1524 1525 1526 1527 1528\n",
      " 1529 1530 ... 1971 1972 1973 1974 1975 1976 1977 1978 1979 1980 1981 1982\n",
      " 1983 1984 1985 1986 1987 1988 1989 1990 1991 1992 1993 1994 1995 1996\n",
      " 1997 1998 1999 2000]\n",
      "TRAIN: [   0    1    2    3    4    5    6    7    8    9   10   11   12   13\n",
      "   14   15   16   17   18   19   20   21   22   23   24   25   26   27\n",
      "   28   29 ... 1971 1972 1973 1974 1975 1976 1977 1978 1979 1980 1981 1982\n",
      " 1983 1984 1985 1986 1987 1988 1989 1990 1991 1992 1993 1994 1995 1996\n",
      " 1997 1998 1999 2000] TEST: [2001 2002 2003 2004 2005 2006 2007 2008 2009 2010 2011 2012 2013 2014\n",
      " 2015 2016 2017 2018 2019 2020 2021 2022 2023 2024 2025 2026 2027 2028\n",
      " 2029 2030 ... 2471 2472 2473 2474 2475 2476 2477 2478 2479 2480 2481 2482\n",
      " 2483 2484 2485 2486 2487 2488 2489 2490 2491 2492 2493 2494 2495 2496\n",
      " 2497 2498 2499 2500]\n"
     ]
    }
   ],
   "source": [
    "# Do a time series cross-validation on the test set by splitting it to k folds and doing a \"rolling\"\n",
    "# validation against a validation fold, then averaging out the metrics.\n",
    "splits = 4 # This is the number of splits/folds in the rolling validation.\n",
    "tscv = TimeSeriesSplit(n_splits=splits)\n",
    "\n",
    "for train_index, test_index in tscv.split(X_train): # Rolling cross-validation happens inside this loop.\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6759\u001b[0m       \u001b[32m0.5895\u001b[0m        \u001b[35m0.6943\u001b[0m  0.0273\n",
      "      2        \u001b[36m0.6525\u001b[0m       \u001b[32m0.6316\u001b[0m        \u001b[35m0.6797\u001b[0m  0.0256\n",
      "      3        \u001b[36m0.6288\u001b[0m       \u001b[32m0.8526\u001b[0m        \u001b[35m0.6648\u001b[0m  0.0249\n",
      "      4        \u001b[36m0.6047\u001b[0m       0.8316        \u001b[35m0.6502\u001b[0m  0.0244\n",
      "      5        \u001b[36m0.5805\u001b[0m       0.8211        \u001b[35m0.6360\u001b[0m  0.0247\n",
      "      6        \u001b[36m0.5554\u001b[0m       0.8526        \u001b[35m0.6220\u001b[0m  0.0247\n",
      "      7        \u001b[36m0.5303\u001b[0m       0.8211        \u001b[35m0.6100\u001b[0m  0.0248\n",
      "      8        \u001b[36m0.5047\u001b[0m       0.7895        \u001b[35m0.5977\u001b[0m  0.0245\n",
      "      9        \u001b[36m0.4796\u001b[0m       0.7895        \u001b[35m0.5857\u001b[0m  0.0246\n",
      "     10        \u001b[36m0.4545\u001b[0m       0.7895        \u001b[35m0.5739\u001b[0m  0.0246\n",
      "     11        \u001b[36m0.4304\u001b[0m       0.7895        \u001b[35m0.5634\u001b[0m  0.0250\n",
      "     12        \u001b[36m0.4064\u001b[0m       0.7895        \u001b[35m0.5531\u001b[0m  0.0245\n",
      "     13        \u001b[36m0.3840\u001b[0m       0.8000        \u001b[35m0.5438\u001b[0m  0.0245\n",
      "     14        \u001b[36m0.3628\u001b[0m       0.8000        \u001b[35m0.5349\u001b[0m  0.0245\n",
      "     15        \u001b[36m0.3432\u001b[0m       0.8000        \u001b[35m0.5271\u001b[0m  0.0241\n",
      "     16        \u001b[36m0.3254\u001b[0m       0.8000        \u001b[35m0.5180\u001b[0m  0.0244\n",
      "     17        \u001b[36m0.3087\u001b[0m       0.8105        \u001b[35m0.5103\u001b[0m  0.0242\n",
      "     18        \u001b[36m0.2933\u001b[0m       0.8105        \u001b[35m0.5023\u001b[0m  0.0247\n",
      "     19        \u001b[36m0.2792\u001b[0m       0.8105        \u001b[35m0.4984\u001b[0m  0.0250\n",
      "     20        \u001b[36m0.2653\u001b[0m       0.8105        \u001b[35m0.4898\u001b[0m  0.0246\n",
      "     21        \u001b[36m0.2524\u001b[0m       0.8105        \u001b[35m0.4820\u001b[0m  0.0251\n",
      "     22        \u001b[36m0.2399\u001b[0m       0.8105        \u001b[35m0.4759\u001b[0m  0.0245\n",
      "     23        \u001b[36m0.2279\u001b[0m       0.8211        \u001b[35m0.4690\u001b[0m  0.0251\n",
      "     24        \u001b[36m0.2168\u001b[0m       0.8211        \u001b[35m0.4602\u001b[0m  0.0250\n",
      "     25        \u001b[36m0.2068\u001b[0m       0.8105        0.4616  0.0246\n",
      "     26        \u001b[36m0.1955\u001b[0m       0.8211        \u001b[35m0.4514\u001b[0m  0.0242\n",
      "     27        \u001b[36m0.1860\u001b[0m       0.8105        \u001b[35m0.4512\u001b[0m  0.0250\n",
      "     28        \u001b[36m0.1770\u001b[0m       0.8105        \u001b[35m0.4457\u001b[0m  0.0245\n",
      "     29        \u001b[36m0.1685\u001b[0m       0.8105        \u001b[35m0.4424\u001b[0m  0.0250\n",
      "     30        \u001b[36m0.1610\u001b[0m       0.8105        \u001b[35m0.4403\u001b[0m  0.0248\n",
      "     31        \u001b[36m0.1540\u001b[0m       0.8105        0.4403  0.0248\n",
      "     32        \u001b[36m0.1475\u001b[0m       0.8105        \u001b[35m0.4357\u001b[0m  0.0246\n",
      "     33        \u001b[36m0.1411\u001b[0m       0.8105        0.4359  0.0252\n",
      "     34        \u001b[36m0.1341\u001b[0m       0.8105        \u001b[35m0.4345\u001b[0m  0.0248\n",
      "     35        \u001b[36m0.1287\u001b[0m       0.8105        \u001b[35m0.4307\u001b[0m  0.0250\n",
      "     36        \u001b[36m0.1231\u001b[0m       0.8000        0.4308  0.0249\n",
      "     37        \u001b[36m0.1171\u001b[0m       0.8000        0.4351  0.0245\n",
      "     38        \u001b[36m0.1131\u001b[0m       0.8000        0.4318  0.0252\n",
      "     39        \u001b[36m0.1089\u001b[0m       0.8000        0.4429  0.0246\n",
      "     40        \u001b[36m0.1036\u001b[0m       0.8000        0.4323  0.0244\n",
      "     41        \u001b[36m0.0993\u001b[0m       0.7895        0.4470  0.0255\n",
      "     42        \u001b[36m0.0968\u001b[0m       0.7895        0.4493  0.0256\n",
      "     43        \u001b[36m0.0929\u001b[0m       0.8105        \u001b[35m0.4224\u001b[0m  0.0253\n",
      "     44        \u001b[36m0.0911\u001b[0m       0.8000        0.4457  0.0249\n",
      "     45        \u001b[36m0.0856\u001b[0m       0.8000        0.4414  0.0249\n",
      "     46        \u001b[36m0.0832\u001b[0m       0.7895        0.4629  0.0251\n",
      "     47        \u001b[36m0.0809\u001b[0m       0.8000        0.4463  0.0247\n",
      "     48        \u001b[36m0.0755\u001b[0m       0.8000        0.4549  0.0244\n",
      "     49        \u001b[36m0.0721\u001b[0m       0.7895        0.4643  0.0244\n",
      "     50        \u001b[36m0.0704\u001b[0m       0.7895        0.4727  0.0241\n",
      "0.6041263157894736 0.8127659574468085\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6533\u001b[0m       \u001b[32m0.5128\u001b[0m        \u001b[35m0.6854\u001b[0m  0.0506\n",
      "      2        \u001b[36m0.6251\u001b[0m       \u001b[32m0.5231\u001b[0m        \u001b[35m0.6784\u001b[0m  0.0505\n",
      "      3        \u001b[36m0.5930\u001b[0m       \u001b[32m0.5641\u001b[0m        \u001b[35m0.6718\u001b[0m  0.0509\n",
      "      4        \u001b[36m0.5564\u001b[0m       \u001b[32m0.7692\u001b[0m        \u001b[35m0.6632\u001b[0m  0.0498\n",
      "      5        \u001b[36m0.5165\u001b[0m       \u001b[32m0.8513\u001b[0m        \u001b[35m0.6524\u001b[0m  0.0495\n",
      "      6        \u001b[36m0.4756\u001b[0m       0.8513        \u001b[35m0.6433\u001b[0m  0.0499\n",
      "      7        \u001b[36m0.4352\u001b[0m       0.8205        \u001b[35m0.6327\u001b[0m  0.0491\n",
      "      8        \u001b[36m0.3970\u001b[0m       0.8462        \u001b[35m0.6235\u001b[0m  0.0492\n",
      "      9        \u001b[36m0.3622\u001b[0m       0.8000        \u001b[35m0.6186\u001b[0m  0.0488\n",
      "     10        \u001b[36m0.3313\u001b[0m       0.7744        \u001b[35m0.6175\u001b[0m  0.0489\n",
      "     11        \u001b[36m0.3047\u001b[0m       0.7744        \u001b[35m0.6174\u001b[0m  0.0492\n",
      "     12        \u001b[36m0.2815\u001b[0m       0.7538        0.6183  0.0488\n",
      "     13        \u001b[36m0.2609\u001b[0m       0.7538        \u001b[35m0.6160\u001b[0m  0.0499\n",
      "     14        \u001b[36m0.2435\u001b[0m       0.7333        \u001b[35m0.6111\u001b[0m  0.0494\n",
      "     15        \u001b[36m0.2270\u001b[0m       0.7077        \u001b[35m0.6081\u001b[0m  0.0496\n",
      "     16        \u001b[36m0.2128\u001b[0m       0.6821        0.6089  0.0493\n",
      "     17        \u001b[36m0.1993\u001b[0m       0.6564        0.6109  0.0492\n",
      "     18        \u001b[36m0.1872\u001b[0m       0.6564        0.6083  0.0488\n",
      "     19        \u001b[36m0.1799\u001b[0m       0.6564        \u001b[35m0.6072\u001b[0m  0.0486\n",
      "     20        \u001b[36m0.1688\u001b[0m       0.6205        0.6192  0.0487\n",
      "     21        \u001b[36m0.1593\u001b[0m       0.6103        0.6206  0.0487\n",
      "     22        \u001b[36m0.1516\u001b[0m       0.5744        0.6306  0.0492\n",
      "     23        \u001b[36m0.1459\u001b[0m       0.5436        0.6432  0.0490\n",
      "     24        \u001b[36m0.1382\u001b[0m       0.5538        0.6426  0.0491\n",
      "     25        \u001b[36m0.1312\u001b[0m       0.5436        0.6557  0.0495\n",
      "     26        \u001b[36m0.1247\u001b[0m       0.4923        0.6758  0.0487\n",
      "     27        \u001b[36m0.1194\u001b[0m       0.5077        0.6750  0.0492\n",
      "     28        \u001b[36m0.1157\u001b[0m       0.5333        0.6728  0.0490\n",
      "     29        \u001b[36m0.1109\u001b[0m       0.4872        0.7001  0.0489\n",
      "     30        \u001b[36m0.1061\u001b[0m       0.4923        0.7023  0.0488\n",
      "     31        \u001b[36m0.1011\u001b[0m       0.4821        0.7273  0.0488\n",
      "     32        \u001b[36m0.1001\u001b[0m       0.4769        0.7304  0.0490\n",
      "     33        \u001b[36m0.0945\u001b[0m       0.4667        0.7413  0.0490\n",
      "     34        \u001b[36m0.0906\u001b[0m       0.4615        0.7428  0.0491\n",
      "     35        \u001b[36m0.0878\u001b[0m       0.4513        0.7599  0.0491\n",
      "     36        \u001b[36m0.0857\u001b[0m       0.4410        0.7606  0.0492\n",
      "     37        \u001b[36m0.0837\u001b[0m       0.4410        0.7685  0.0490\n",
      "     38        \u001b[36m0.0779\u001b[0m       0.4410        0.7764  0.0492\n",
      "     39        \u001b[36m0.0716\u001b[0m       0.4410        0.7851  0.0488\n",
      "     40        0.0718       0.4410        0.8015  0.0488\n",
      "     41        \u001b[36m0.0677\u001b[0m       0.4256        0.8030  0.0491\n",
      "     42        \u001b[36m0.0660\u001b[0m       0.4256        0.8007  0.0487\n",
      "     43        \u001b[36m0.0630\u001b[0m       0.4103        0.8145  0.0491\n",
      "     44        \u001b[36m0.0614\u001b[0m       0.4103        0.8313  0.0490\n",
      "     45        \u001b[36m0.0608\u001b[0m       0.4051        0.8398  0.0499\n",
      "     46        \u001b[36m0.0534\u001b[0m       0.4051        0.8408  0.0496\n",
      "     47        \u001b[36m0.0497\u001b[0m       0.4051        0.8382  0.0493\n",
      "     48        \u001b[36m0.0492\u001b[0m       0.4051        0.8622  0.0494\n",
      "     49        \u001b[36m0.0482\u001b[0m       0.4051        0.8601  0.0491\n",
      "     50        \u001b[36m0.0472\u001b[0m       0.4051        0.8776  0.0487\n",
      "0.8468965517241378 0.42340425531914894\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6553\u001b[0m       \u001b[32m0.8237\u001b[0m        \u001b[35m0.6463\u001b[0m  0.0734\n",
      "      2        \u001b[36m0.6228\u001b[0m       \u001b[32m0.8407\u001b[0m        \u001b[35m0.6365\u001b[0m  0.0746\n",
      "      3        \u001b[36m0.5792\u001b[0m       \u001b[32m0.8644\u001b[0m        \u001b[35m0.6301\u001b[0m  0.0758\n",
      "      4        \u001b[36m0.5198\u001b[0m       0.8271        \u001b[35m0.6216\u001b[0m  0.0740\n",
      "      5        \u001b[36m0.4462\u001b[0m       0.8000        \u001b[35m0.5946\u001b[0m  0.0736\n",
      "      6        \u001b[36m0.3723\u001b[0m       0.7559        \u001b[35m0.5501\u001b[0m  0.0734\n",
      "      7        \u001b[36m0.3152\u001b[0m       0.7593        \u001b[35m0.5106\u001b[0m  0.0735\n",
      "      8        \u001b[36m0.2763\u001b[0m       0.7390        \u001b[35m0.4921\u001b[0m  0.0738\n",
      "      9        \u001b[36m0.2486\u001b[0m       0.7119        \u001b[35m0.4857\u001b[0m  0.0754\n",
      "     10        \u001b[36m0.2270\u001b[0m       0.6780        0.4895  0.0742\n",
      "     11        \u001b[36m0.2082\u001b[0m       0.6508        0.5004  0.0736\n",
      "     12        \u001b[36m0.1938\u001b[0m       0.6339        0.5040  0.0737\n",
      "     13        \u001b[36m0.1811\u001b[0m       0.6068        0.5108  0.0733\n",
      "     14        \u001b[36m0.1695\u001b[0m       0.6068        0.5143  0.0733\n",
      "     15        \u001b[36m0.1613\u001b[0m       0.6034        0.5171  0.0729\n",
      "     16        \u001b[36m0.1529\u001b[0m       0.6000        0.5235  0.0735\n",
      "     17        \u001b[36m0.1458\u001b[0m       0.6068        0.5232  0.0733\n",
      "     18        \u001b[36m0.1391\u001b[0m       0.6000        0.5357  0.0737\n",
      "     19        \u001b[36m0.1326\u001b[0m       0.6000        0.5344  0.0736\n",
      "     20        \u001b[36m0.1282\u001b[0m       0.5966        0.5481  0.0740\n",
      "     21        \u001b[36m0.1246\u001b[0m       0.5966        0.5507  0.0745\n",
      "     22        \u001b[36m0.1195\u001b[0m       0.5898        0.5626  0.0734\n",
      "     23        \u001b[36m0.1134\u001b[0m       0.5864        0.5662  0.0740\n",
      "     24        \u001b[36m0.1108\u001b[0m       0.5864        0.5770  0.0731\n",
      "     25        \u001b[36m0.1104\u001b[0m       0.5831        0.5892  0.0748\n",
      "     26        \u001b[36m0.1083\u001b[0m       0.5729        0.6004  0.0736\n",
      "     27        \u001b[36m0.0989\u001b[0m       0.5729        0.6093  0.0732\n",
      "     28        \u001b[36m0.0968\u001b[0m       0.5763        0.6104  0.0732\n",
      "     29        \u001b[36m0.0933\u001b[0m       0.5763        0.6190  0.0737\n",
      "     30        \u001b[36m0.0904\u001b[0m       0.5729        0.6264  0.0744\n",
      "     31        \u001b[36m0.0878\u001b[0m       0.5695        0.6383  0.0736\n",
      "     32        \u001b[36m0.0854\u001b[0m       0.5627        0.6453  0.0741\n",
      "     33        \u001b[36m0.0832\u001b[0m       0.5661        0.6459  0.0737\n",
      "     34        \u001b[36m0.0798\u001b[0m       0.5661        0.6633  0.0732\n",
      "     35        \u001b[36m0.0792\u001b[0m       0.5661        0.6687  0.0745\n",
      "     36        \u001b[36m0.0770\u001b[0m       0.5627        0.6936  0.0747\n",
      "     37        \u001b[36m0.0731\u001b[0m       0.5661        0.6968  0.0738\n",
      "     38        \u001b[36m0.0693\u001b[0m       0.5661        0.7078  0.0730\n",
      "     39        \u001b[36m0.0679\u001b[0m       0.5661        0.7137  0.0734\n",
      "     40        \u001b[36m0.0670\u001b[0m       0.5661        0.7214  0.0736\n",
      "     41        \u001b[36m0.0643\u001b[0m       0.5627        0.7474  0.0738\n",
      "     42        \u001b[36m0.0615\u001b[0m       0.5627        0.7569  0.0751\n",
      "     43        \u001b[36m0.0590\u001b[0m       0.5661        0.7639  0.0739\n",
      "     44        0.0609       0.5661        0.7765  0.0736\n",
      "     45        \u001b[36m0.0577\u001b[0m       0.5661        0.7836  0.0729\n",
      "     46        \u001b[36m0.0549\u001b[0m       0.5661        0.7918  0.0730\n",
      "     47        \u001b[36m0.0531\u001b[0m       0.5695        0.7981  0.0740\n",
      "     48        \u001b[36m0.0524\u001b[0m       0.5661        0.8127  0.0771\n",
      "     49        \u001b[36m0.0508\u001b[0m       0.5763        0.8139  0.0756\n",
      "     50        \u001b[36m0.0481\u001b[0m       0.5695        0.8256  0.0769\n",
      "0.7642692939244663 0.4595744680851064\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6198\u001b[0m       \u001b[32m0.8228\u001b[0m        \u001b[35m0.6454\u001b[0m  0.1017\n",
      "      2        \u001b[36m0.5328\u001b[0m       0.5873        0.6648  0.1001\n",
      "      3        \u001b[36m0.4416\u001b[0m       0.5342        0.6678  0.0994\n",
      "      4        \u001b[36m0.3601\u001b[0m       0.4886        0.6748  0.0982\n",
      "      5        \u001b[36m0.2972\u001b[0m       0.5063        0.6653  0.0990\n",
      "      6        \u001b[36m0.2526\u001b[0m       0.5139        \u001b[35m0.6403\u001b[0m  0.0976\n",
      "      7        \u001b[36m0.2206\u001b[0m       0.5165        \u001b[35m0.6230\u001b[0m  0.0989\n",
      "      8        \u001b[36m0.1968\u001b[0m       0.5392        \u001b[35m0.6060\u001b[0m  0.0986\n",
      "      9        \u001b[36m0.1808\u001b[0m       0.5342        \u001b[35m0.5930\u001b[0m  0.0990\n",
      "     10        \u001b[36m0.1690\u001b[0m       0.5342        0.6049  0.0985\n",
      "     11        \u001b[36m0.1614\u001b[0m       0.5823        \u001b[35m0.5798\u001b[0m  0.0992\n",
      "     12        \u001b[36m0.1523\u001b[0m       0.6127        \u001b[35m0.5669\u001b[0m  0.0979\n",
      "     13        \u001b[36m0.1458\u001b[0m       0.6076        0.5710  0.0980\n",
      "     14        \u001b[36m0.1396\u001b[0m       0.6253        \u001b[35m0.5549\u001b[0m  0.0977\n",
      "     15        \u001b[36m0.1347\u001b[0m       0.6203        0.5669  0.0980\n",
      "     16        \u001b[36m0.1281\u001b[0m       0.6253        0.5595  0.0995\n",
      "     17        \u001b[36m0.1249\u001b[0m       0.6228        0.5709  0.0996\n",
      "     18        \u001b[36m0.1182\u001b[0m       0.6304        \u001b[35m0.5532\u001b[0m  0.1003\n",
      "     19        \u001b[36m0.1150\u001b[0m       0.6304        0.5617  0.0982\n",
      "     20        \u001b[36m0.1145\u001b[0m       0.6304        0.5756  0.0996\n",
      "     21        \u001b[36m0.1068\u001b[0m       0.6127        0.6018  0.0979\n",
      "     22        \u001b[36m0.1067\u001b[0m       0.6203        0.5943  0.0978\n",
      "     23        \u001b[36m0.1024\u001b[0m       0.6228        0.5989  0.0972\n",
      "     24        \u001b[36m0.0974\u001b[0m       0.6025        0.6382  0.0977\n",
      "     25        0.1027       0.5772        0.6506  0.0973\n",
      "     26        \u001b[36m0.0926\u001b[0m       0.5797        0.6576  0.0973\n",
      "     27        \u001b[36m0.0843\u001b[0m       0.5696        0.6705  0.0990\n",
      "     28        \u001b[36m0.0813\u001b[0m       0.5620        0.6836  0.0989\n",
      "     29        \u001b[36m0.0792\u001b[0m       0.5468        0.7030  0.1004\n",
      "     30        \u001b[36m0.0748\u001b[0m       0.5468        0.7136  0.0989\n",
      "     31        0.0761       0.5544        0.7138  0.0987\n",
      "     32        \u001b[36m0.0698\u001b[0m       0.5392        0.7495  0.0983\n",
      "     33        \u001b[36m0.0680\u001b[0m       0.5266        0.7777  0.0987\n",
      "     34        0.0694       0.5367        0.7763  0.0980\n",
      "     35        \u001b[36m0.0675\u001b[0m       0.5367        0.7868  0.0981\n",
      "     36        \u001b[36m0.0645\u001b[0m       0.5316        0.8144  0.0982\n",
      "     37        \u001b[36m0.0620\u001b[0m       0.5316        0.8273  0.1003\n",
      "     38        \u001b[36m0.0563\u001b[0m       0.5241        0.8482  0.0986\n",
      "     39        \u001b[36m0.0561\u001b[0m       0.5241        0.8587  0.0985\n",
      "     40        \u001b[36m0.0523\u001b[0m       0.5241        0.8781  0.0983\n",
      "     41        \u001b[36m0.0519\u001b[0m       0.5215        0.8977  0.0987\n",
      "     42        0.0585       0.5215        0.9105  0.0991\n",
      "     43        \u001b[36m0.0495\u001b[0m       0.5215        0.9228  0.0980\n",
      "     44        \u001b[36m0.0474\u001b[0m       0.5215        0.9455  0.1014\n",
      "     45        0.0485       0.5215        0.9516  0.1032\n",
      "     46        0.0490       0.5114        0.9825  0.1012\n",
      "     47        \u001b[36m0.0443\u001b[0m       0.5165        0.9937  0.0982\n",
      "     48        \u001b[36m0.0421\u001b[0m       0.5165        1.0043  0.0999\n",
      "     49        0.0426       0.5241        0.9859  0.1028\n",
      "     50        \u001b[36m0.0405\u001b[0m       0.5165        1.0255  0.1017\n",
      "0.49094060701203557 0.7638297872340426\n"
     ]
    }
   ],
   "source": [
    "AUC_ROCs = dict()\n",
    "ACCs = dict()\n",
    "model_name = \"LSTM\"\n",
    "print(model_name)\n",
    "AUC_ROCs[model_name] = 0\n",
    "ACCs[model_name] = 0\n",
    "for train_index, test_index in tscv.split(X_train): # Rolling cross-validation happens inside this loop.\n",
    "    X_train_fold, X_validation_fold = X_train.iloc[train_index[:-lag_of_y], X_train.columns != \"USRECD\"], \\\n",
    "        X_train.iloc[test_index[:-lag_of_y], X_train.columns != \"USRECD\"]\n",
    "    y_train_fold, y_validation_fold = y_train.iloc[train_index[lag_of_y:], y_train.columns == \"USRECD\"], \\\n",
    "        y_train.iloc[test_index[lag_of_y:], y_train.columns == \"USRECD\"]\n",
    "\n",
    "    scalers = dict()\n",
    "    for feature in features:\n",
    "        scalers[feature] = StandardScaler()\n",
    "        scalers[feature].fit(X_train_fold[[feature]])\n",
    "        X_train_fold[feature] = scalers[feature].transform(X_train_fold[[feature]])\n",
    "        X_validation_fold[feature] = scalers[feature].transform(X_validation_fold[[feature]])\n",
    "\n",
    "    X_train_fold, y_train_fold = split_sequences(X_train_fold.to_numpy(), y_train_fold.to_numpy(), n_steps=10)\n",
    "    X_train_fold = X_train_fold.astype(np.float32)\n",
    "    y_train_fold = y_train_fold.astype(np.float32)\n",
    "    X_validation_fold, y_validation_fold = split_sequences(X_validation_fold.to_numpy(), y_validation_fold.to_numpy(), n_steps=10)\n",
    "    X_validation_fold = X_validation_fold.astype(np.float32)\n",
    "    y_validation_fold = y_validation_fold.astype(np.float32)\n",
    "    model = get_model()\n",
    "    model.fit(X_train_fold, y_train_fold)\n",
    "    positive_probs = [p[1] for p in model.predict_proba(X_validation_fold)]\n",
    "    AUC_ROC = metrics.roc_auc_score(y_validation_fold, positive_probs)\n",
    "    AUC_ROCs[model_name] += AUC_ROC\n",
    "    predictions = model.predict(X_validation_fold)\n",
    "    ACC = accuracy_score(y_validation_fold, predictions)\n",
    "    ACCs[model_name] += ACC\n",
    "    print(AUC_ROC, ACC)\n",
    "\n",
    "AUC_ROCs[model_name] /= splits\n",
    "ACCs[model_name] /= splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM\n",
      "AUC ROC: 0.6765581921125283\n",
      "accuracy: 0.6148936170212765\n"
     ]
    }
   ],
   "source": [
    "print(model_name)\n",
    "print(f\"AUC ROC: {AUC_ROCs[model_name]}\")\n",
    "print(f\"accuracy: {ACCs[model_name]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5, 0.8560575769692124)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# random guess\n",
    "total = y_train.shape[0]\n",
    "metrics.roc_auc_score(y_train.USRECD, np.zeros(total)), accuracy_score(y_train.USRECD, np.zeros(total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.copy()\n",
    "X_test = X_test.copy()\n",
    "\n",
    "all_scalers = dict()\n",
    "for feature in features:\n",
    "    all_scalers[feature] = StandardScaler()\n",
    "    all_scalers[feature].fit(X_train[[feature]])\n",
    "    X_train[feature] = all_scalers[feature].transform(X_train[[feature]])\n",
    "    X_test[feature] = all_scalers[feature].transform(X_test[[feature]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.8]\n",
      "[6.44]\n",
      "[3.61]\n",
      "[5.88]\n",
      "[2.29]\n",
      "[3.06]\n",
      "[4.71]\n",
      "[1.81]\n",
      "[6.78]\n",
      "[3.18]\n",
      "[12.51]\n",
      "[3.96]\n",
      "[9.69]\n",
      "[0.01]\n",
      "[2.96]\n",
      "[1.81]\n",
      "[1.07]\n",
      "[1.1]\n",
      "[1.57]\n",
      "[-2.89]\n"
     ]
    }
   ],
   "source": [
    "for feature in features:\n",
    "    print(all_scalers[feature].mean_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6003\u001b[0m       \u001b[32m0.8557\u001b[0m        \u001b[35m0.6039\u001b[0m  0.1284\n",
      "      2        \u001b[36m0.5401\u001b[0m       0.8557        \u001b[35m0.5735\u001b[0m  0.1247\n",
      "      3        \u001b[36m0.4584\u001b[0m       0.8557        \u001b[35m0.5425\u001b[0m  0.1249\n",
      "      4        \u001b[36m0.3695\u001b[0m       0.8557        \u001b[35m0.5203\u001b[0m  0.1277\n",
      "      5        \u001b[36m0.2991\u001b[0m       0.8557        \u001b[35m0.5118\u001b[0m  0.1282\n",
      "      6        \u001b[36m0.2517\u001b[0m       0.8397        \u001b[35m0.5055\u001b[0m  0.1271\n",
      "      7        \u001b[36m0.2183\u001b[0m       0.8236        \u001b[35m0.5030\u001b[0m  0.1256\n",
      "      8        \u001b[36m0.1950\u001b[0m       0.8156        0.5094  0.1235\n",
      "      9        \u001b[36m0.1790\u001b[0m       0.8277        0.5067  0.1235\n",
      "     10        \u001b[36m0.1680\u001b[0m       0.8357        0.5040  0.1241\n",
      "     11        \u001b[36m0.1576\u001b[0m       0.8317        0.5041  0.1254\n",
      "     12        \u001b[36m0.1515\u001b[0m       0.8056        \u001b[35m0.5016\u001b[0m  0.1288\n",
      "     13        \u001b[36m0.1428\u001b[0m       0.7375        \u001b[35m0.5003\u001b[0m  0.1254\n",
      "     14        \u001b[36m0.1341\u001b[0m       0.7174        \u001b[35m0.4986\u001b[0m  0.1243\n",
      "     15        \u001b[36m0.1271\u001b[0m       0.6914        0.4994  0.1220\n",
      "     16        \u001b[36m0.1203\u001b[0m       0.7094        0.4999  0.1234\n",
      "     17        \u001b[36m0.1150\u001b[0m       0.6733        0.5015  0.1237\n",
      "     18        \u001b[36m0.1114\u001b[0m       0.6794        0.5028  0.1237\n",
      "     19        \u001b[36m0.1055\u001b[0m       0.6733        0.5102  0.1221\n",
      "     20        \u001b[36m0.1012\u001b[0m       0.6774        0.5105  0.1233\n",
      "     21        \u001b[36m0.0961\u001b[0m       0.6673        0.5191  0.1246\n",
      "     22        \u001b[36m0.0935\u001b[0m       0.6593        0.5270  0.1243\n",
      "     23        \u001b[36m0.0897\u001b[0m       0.6573        0.5331  0.1237\n",
      "     24        \u001b[36m0.0868\u001b[0m       0.6533        0.5440  0.1224\n",
      "     25        \u001b[36m0.0828\u001b[0m       0.6533        0.5466  0.1231\n",
      "     26        \u001b[36m0.0804\u001b[0m       0.6413        0.5559  0.1222\n",
      "     27        \u001b[36m0.0790\u001b[0m       0.6273        0.5696  0.1221\n",
      "     28        \u001b[36m0.0749\u001b[0m       0.6273        0.5757  0.1231\n",
      "     29        \u001b[36m0.0723\u001b[0m       0.6192        0.5853  0.1230\n",
      "     30        \u001b[36m0.0702\u001b[0m       0.6253        0.5926  0.1224\n",
      "     31        \u001b[36m0.0680\u001b[0m       0.6192        0.5999  0.1229\n",
      "     32        \u001b[36m0.0665\u001b[0m       0.6253        0.6094  0.1230\n",
      "     33        \u001b[36m0.0661\u001b[0m       0.6152        0.6178  0.1235\n",
      "     34        \u001b[36m0.0637\u001b[0m       0.6192        0.6202  0.1223\n",
      "     35        \u001b[36m0.0628\u001b[0m       0.6172        0.6208  0.1223\n",
      "     36        \u001b[36m0.0618\u001b[0m       0.6172        0.6348  0.1230\n",
      "     37        \u001b[36m0.0589\u001b[0m       0.6152        0.6401  0.1248\n",
      "     38        0.0590       0.6132        0.6478  0.1251\n",
      "     39        \u001b[36m0.0572\u001b[0m       0.6132        0.6531  0.1243\n",
      "     40        \u001b[36m0.0557\u001b[0m       0.6172        0.6568  0.1239\n",
      "     41        0.0571       0.6152        0.6703  0.1232\n",
      "     42        \u001b[36m0.0542\u001b[0m       0.6152        0.6703  0.1237\n",
      "     43        \u001b[36m0.0532\u001b[0m       0.6152        0.6813  0.1245\n",
      "     44        0.0536       0.6132        0.6861  0.1234\n",
      "     45        \u001b[36m0.0518\u001b[0m       0.6112        0.6975  0.1231\n",
      "     46        0.0520       0.6112        0.7023  0.1223\n",
      "     47        \u001b[36m0.0501\u001b[0m       0.6112        0.7094  0.1232\n",
      "     48        \u001b[36m0.0489\u001b[0m       0.6032        0.7265  0.1237\n",
      "     49        \u001b[36m0.0475\u001b[0m       0.5832        0.7456  0.1246\n",
      "     50        0.0477       0.5731        0.7567  0.1234\n",
      "0.739622641509434\n",
      "0.7992565055762082\n"
     ]
    }
   ],
   "source": [
    "print(model_name)\n",
    "model = get_model()\n",
    "\n",
    "X_train, y_train = split_sequences(X_train.to_numpy(), y_train.to_numpy(), n_steps=10)\n",
    "X_train = X_train.astype(np.float32)\n",
    "y_train = y_train.astype(np.float32)\n",
    "\n",
    "X_test, y_test = split_sequences(X_test.to_numpy(), y_test.to_numpy(), n_steps=10)\n",
    "X_test = X_test.astype(np.float32)\n",
    "y_test = y_test.astype(np.float32)\n",
    "    \n",
    "model.fit(X_train, y_train)\n",
    "positive_probs = [p[1] for p in model.predict_proba(X_test)]\n",
    "AUC_ROC = metrics.roc_auc_score(y_test, positive_probs)\n",
    "print(AUC_ROC)\n",
    "predictions = model.predict(X_test)\n",
    "ACC = accuracy_score(y_test, predictions)\n",
    "print(ACC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
