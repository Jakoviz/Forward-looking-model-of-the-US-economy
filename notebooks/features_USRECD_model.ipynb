{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import figure\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import TimeSeriesSplit, train_test_split\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Settings:\n",
    "pd.set_option('display.width', 190)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 20)\n",
    "pd.set_option('max_colwidth', 200)\n",
    "pd.options.display.float_format = '{:.4f}'.format\n",
    "plt.style.use('default')\n",
    "np.set_printoptions(threshold = 30, edgeitems = 30, precision = 2, suppress = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_path = \"../merged_data/features_USRECD.csv\"\n",
    "features = [\"BCI\", \"BCIp\", \"BCIg\", 'IE_SP_Comp', 'IE_SP_Dividend', 'IE_SP_Earnings', 'IE_Consumer_CPI', 'IE_Long_Interest', 'IE_Real_Price', 'IE_Real_Dividend', 'IE_Return_Price', 'IE_Real_Earnings',\n",
    "                'IE_Scaled_Earnings', 'IE_Monthly_Returns', 'IE_Real_Returns']\n",
    "model_names = [\"Logistic Regression\", \"Penalized SVM\", \"Random Forest\"]\n",
    "get_models = [lambda: linear_model.LogisticRegression(), lambda: svm.SVC(kernel='linear', class_weight='balanced', probability=True), \n",
    "          lambda: RandomForestClassifier()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data and do a little bit of wrangling:\n",
    "df = pd.read_csv(df_path)\n",
    "df.Date = pd.to_datetime(df.Date)\n",
    "df = df.sort_values(ascending=True, by=\"Date\")\n",
    "df = df.set_index(\"Date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into training and test sets and hold out the test set until the end, so that it remains \"unseen\".\n",
    "lag_of_y = 21 # This is the lag we introduce to the target variable so that we assess the indicator's \n",
    "              # ability to predict the target variable this many steps into the future.\n",
    "              # With BCI, a lag of 21 data points corresponds to about half a year.\n",
    "        \n",
    "X_train, X_test, y_train, y_test = train_test_split(df.iloc[:-lag_of_y, df.columns != \"USRECD\"], \\\n",
    "    df.iloc[lag_of_y:, df.columns == \"USRECD\"], test_size=0.1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for feature in features:\n",
    "#     plt.figure()\n",
    "#     X_train[feature].hist(bins = 50)\n",
    "#     plt.xlabel(feature,fontsize=15)\n",
    "#     plt.ylabel(\"Frequency\",fontsize=15)\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29 ... 471 472 473 474 475\n",
      " 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493\n",
      " 494 495 496 497 498 499 500] TEST: [ 501  502  503  504  505  506  507  508  509  510  511  512  513  514\n",
      "  515  516  517  518  519  520  521  522  523  524  525  526  527  528\n",
      "  529  530 ...  971  972  973  974  975  976  977  978  979  980  981  982\n",
      "  983  984  985  986  987  988  989  990  991  992  993  994  995  996\n",
      "  997  998  999 1000]\n",
      "TRAIN: [   0    1    2    3    4    5    6    7    8    9   10   11   12   13\n",
      "   14   15   16   17   18   19   20   21   22   23   24   25   26   27\n",
      "   28   29 ...  971  972  973  974  975  976  977  978  979  980  981  982\n",
      "  983  984  985  986  987  988  989  990  991  992  993  994  995  996\n",
      "  997  998  999 1000] TEST: [1001 1002 1003 1004 1005 1006 1007 1008 1009 1010 1011 1012 1013 1014\n",
      " 1015 1016 1017 1018 1019 1020 1021 1022 1023 1024 1025 1026 1027 1028\n",
      " 1029 1030 ... 1471 1472 1473 1474 1475 1476 1477 1478 1479 1480 1481 1482\n",
      " 1483 1484 1485 1486 1487 1488 1489 1490 1491 1492 1493 1494 1495 1496\n",
      " 1497 1498 1499 1500]\n",
      "TRAIN: [   0    1    2    3    4    5    6    7    8    9   10   11   12   13\n",
      "   14   15   16   17   18   19   20   21   22   23   24   25   26   27\n",
      "   28   29 ... 1471 1472 1473 1474 1475 1476 1477 1478 1479 1480 1481 1482\n",
      " 1483 1484 1485 1486 1487 1488 1489 1490 1491 1492 1493 1494 1495 1496\n",
      " 1497 1498 1499 1500] TEST: [1501 1502 1503 1504 1505 1506 1507 1508 1509 1510 1511 1512 1513 1514\n",
      " 1515 1516 1517 1518 1519 1520 1521 1522 1523 1524 1525 1526 1527 1528\n",
      " 1529 1530 ... 1971 1972 1973 1974 1975 1976 1977 1978 1979 1980 1981 1982\n",
      " 1983 1984 1985 1986 1987 1988 1989 1990 1991 1992 1993 1994 1995 1996\n",
      " 1997 1998 1999 2000]\n",
      "TRAIN: [   0    1    2    3    4    5    6    7    8    9   10   11   12   13\n",
      "   14   15   16   17   18   19   20   21   22   23   24   25   26   27\n",
      "   28   29 ... 1971 1972 1973 1974 1975 1976 1977 1978 1979 1980 1981 1982\n",
      " 1983 1984 1985 1986 1987 1988 1989 1990 1991 1992 1993 1994 1995 1996\n",
      " 1997 1998 1999 2000] TEST: [2001 2002 2003 2004 2005 2006 2007 2008 2009 2010 2011 2012 2013 2014\n",
      " 2015 2016 2017 2018 2019 2020 2021 2022 2023 2024 2025 2026 2027 2028\n",
      " 2029 2030 ... 2471 2472 2473 2474 2475 2476 2477 2478 2479 2480 2481 2482\n",
      " 2483 2484 2485 2486 2487 2488 2489 2490 2491 2492 2493 2494 2495 2496\n",
      " 2497 2498 2499 2500]\n"
     ]
    }
   ],
   "source": [
    "# Do a time series cross-validation on the test set by splitting it to k folds and doing a \"rolling\"\n",
    "# validation against a validation fold, then averaging out the metrics.\n",
    "splits = 4 # This is the number of splits/folds in the rolling validation.\n",
    "tscv = TimeSeriesSplit(n_splits=splits)\n",
    "\n",
    "for train_index, test_index in tscv.split(X_train): # Rolling cross-validation happens inside this loop.\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression\n",
      "0.9215186403508772 0.4112734864300626\n",
      "0.7494851994851995 0.9269311064718163\n",
      "0.9308236808236807 0.4175365344467641\n",
      "0.829880427137285 0.837160751565762\n",
      "Penalized SVM\n",
      "0.7604166666666666 0.3695198329853862\n",
      "0.7662162162162163 0.8997912317327766\n",
      "0.9250321750321749 0.2045929018789144\n",
      "0.8426689686041307 0.7891440501043842\n",
      "Random Forest\n",
      "0.5756441885964911 0.8016701461377871\n",
      "0.9490669240669241 0.9227557411273486\n",
      "0.9253217503217503 0.9269311064718163\n",
      "0.8994341070400921 0.906054279749478\n"
     ]
    }
   ],
   "source": [
    "AUC_ROCs = dict()\n",
    "ACCs = dict()\n",
    "for model_name, get_model in zip(model_names, get_models):\n",
    "    print(model_name)\n",
    "    AUC_ROCs[model_name] = 0\n",
    "    ACCs[model_name] = 0\n",
    "    for train_index, test_index in tscv.split(X_train): # Rolling cross-validation happens inside this loop.\n",
    "        X_train_fold, X_validation_fold = X_train.iloc[train_index[:-lag_of_y], X_train.columns != \"USRECD\"], \\\n",
    "            X_train.iloc[test_index[:-lag_of_y], X_train.columns != \"USRECD\"]\n",
    "        y_train_fold, y_validation_fold = y_train.iloc[train_index[lag_of_y:], y_train.columns == \"USRECD\"], \\\n",
    "            y_train.iloc[test_index[lag_of_y:], y_train.columns == \"USRECD\"]\n",
    "            \n",
    "        scalers = dict()\n",
    "        for feature in features:\n",
    "            scalers[feature] = StandardScaler()\n",
    "            scalers[feature].fit(X_train_fold[[feature]])\n",
    "            X_train_fold[feature] = scalers[feature].transform(X_train_fold[[feature]])\n",
    "            X_validation_fold[feature] = scalers[feature].transform(X_validation_fold[[feature]])\n",
    "            \n",
    "        model = get_model()\n",
    "        model.fit(X_train_fold[features], y_train_fold[\"USRECD\"])\n",
    "        positive_probs = [p[1] for p in model.predict_proba(X_validation_fold[features])]\n",
    "        AUC_ROC = metrics.roc_auc_score(y_validation_fold, positive_probs)\n",
    "        AUC_ROCs[model_name] += AUC_ROC\n",
    "        predictions = model.predict(X_validation_fold[features])\n",
    "        ACC = accuracy_score(y_validation_fold, predictions)\n",
    "        ACCs[model_name] += ACC\n",
    "        print(AUC_ROC, ACC)\n",
    "        \n",
    "    AUC_ROCs[model_name] /= splits\n",
    "    ACCs[model_name] /= splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression\n",
      "AUC ROC: 0.8579269869492605\n",
      "accuracy: 0.6482254697286012\n",
      "Penalized SVM\n",
      "AUC ROC: 0.8235835066297972\n",
      "accuracy: 0.5657620041753654\n",
      "Random Forest\n",
      "AUC ROC: 0.8373667425063144\n",
      "accuracy: 0.8893528183716075\n"
     ]
    }
   ],
   "source": [
    "for model_name in model_names:\n",
    "    print(model_name)\n",
    "    print(f\"AUC ROC: {AUC_ROCs[model_name]}\")\n",
    "    print(f\"accuracy: {ACCs[model_name]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5, 0.8560575769692124)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# random guess\n",
    "total = y_train.shape[0]\n",
    "metrics.roc_auc_score(y_train.USRECD, np.zeros(total)), accuracy_score(y_train.USRECD, np.zeros(total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "USRECD\n",
       "0         274\n",
       "1           4\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.copy()\n",
    "X_test = X_test.copy()\n",
    "\n",
    "all_scalers = dict()\n",
    "for feature in features:\n",
    "    all_scalers[feature] = StandardScaler()\n",
    "    all_scalers[feature].fit(X_train[[feature]])\n",
    "    X_train[feature] = all_scalers[feature].transform(X_train[[feature]])\n",
    "    X_test[feature] = all_scalers[feature].transform(X_test[[feature]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.8]\n",
      "[6.44]\n",
      "[3.61]\n",
      "[5.88]\n",
      "[2.29]\n",
      "[3.06]\n",
      "[4.71]\n",
      "[1.81]\n",
      "[6.78]\n",
      "[3.18]\n",
      "[12.51]\n",
      "[3.96]\n",
      "[9.69]\n",
      "[0.01]\n",
      "[2.96]\n"
     ]
    }
   ],
   "source": [
    "for feature in features:\n",
    "    print(all_scalers[feature].mean_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression\n",
      "0.6605839416058394\n",
      "0.6546762589928058\n",
      "Penalized SVM\n",
      "0.6624087591240876\n",
      "0.6726618705035972\n",
      "Random Forest\n",
      "0.38503649635036497\n",
      "0.9856115107913669\n"
     ]
    }
   ],
   "source": [
    "for model_name, get_model in zip(model_names, get_models):\n",
    "    print(model_name)\n",
    "    model = get_model()\n",
    "    model.fit(X_train[features], y_train[\"USRECD\"])\n",
    "    positive_probs = [p[1] for p in model.predict_proba(X_test[features])]\n",
    "    AUC_ROC = metrics.roc_auc_score(y_test, positive_probs)\n",
    "    print(AUC_ROC)\n",
    "    predictions = model.predict(X_test[features])\n",
    "    ACC = accuracy_score(y_test, predictions)\n",
    "    print(ACC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
