{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import figure\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import TimeSeriesSplit, train_test_split\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Settings:\n",
    "pd.set_option('display.width', 190)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 20)\n",
    "pd.set_option('max_colwidth', 200)\n",
    "pd.options.display.float_format = '{:.4f}'.format\n",
    "plt.style.use('default')\n",
    "np.set_printoptions(threshold = 30, edgeitems = 30, precision = 2, suppress = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_path = \"../merged_data/features_USRECD.csv\"\n",
    "features = [\"BCI\", \"BCIp\", \"BCIg\", 'IE_SP_Comp', 'IE_SP_Dividend', 'IE_SP_Earnings', 'IE_Consumer_CPI', 'IE_Long_Interest', 'IE_Real_Price', 'IE_Real_Dividend', 'IE_Return_Price', 'IE_Real_Earnings',\n",
    "                'IE_Scaled_Earnings', 'IE_Monthly_Returns', 'IE_Real_Returns', \"YC_10_Year\", \"YC_3_Month\", \"YC_3_Month_Bond\", \"YC_Spread\", \"YC_Rec_Prob\"]\n",
    "model_names = [\"Logistic Regression\", \"Penalized SVM\", \"Random Forest\"]\n",
    "get_models = [lambda: linear_model.LogisticRegression(), lambda: svm.SVC(kernel='linear', class_weight='balanced', probability=True), \n",
    "          lambda: RandomForestClassifier()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BCI</th>\n",
       "      <th>BCIp</th>\n",
       "      <th>BCIg</th>\n",
       "      <th>USRECD</th>\n",
       "      <th>IE_SP_Comp</th>\n",
       "      <th>IE_SP_Dividend</th>\n",
       "      <th>IE_SP_Earnings</th>\n",
       "      <th>IE_Consumer_CPI</th>\n",
       "      <th>IE_Long_Interest</th>\n",
       "      <th>IE_Real_Price</th>\n",
       "      <th>IE_Real_Dividend</th>\n",
       "      <th>IE_Return_Price</th>\n",
       "      <th>IE_Real_Earnings</th>\n",
       "      <th>IE_Scaled_Earnings</th>\n",
       "      <th>IE_Monthly_Returns</th>\n",
       "      <th>IE_Real_Returns</th>\n",
       "      <th>YC_10_Year</th>\n",
       "      <th>YC_3_Month</th>\n",
       "      <th>YC_3_Month_Bond</th>\n",
       "      <th>YC_Spread</th>\n",
       "      <th>YC_Rec_Prob</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1967-02-09</th>\n",
       "      <td>4.6052</td>\n",
       "      <td>6.5870</td>\n",
       "      <td>3.4751</td>\n",
       "      <td>0</td>\n",
       "      <td>4.4362</td>\n",
       "      <td>1.0578</td>\n",
       "      <td>1.7084</td>\n",
       "      <td>3.4935</td>\n",
       "      <td>1.5217</td>\n",
       "      <td>6.5522</td>\n",
       "      <td>3.1739</td>\n",
       "      <td>11.4502</td>\n",
       "      <td>3.8238</td>\n",
       "      <td>8.7218</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>2.5153</td>\n",
       "      <td>1.5217</td>\n",
       "      <td>1.5518</td>\n",
       "      <td>1.5776</td>\n",
       "      <td>1.2065</td>\n",
       "      <td>-1.1432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1967-02-16</th>\n",
       "      <td>4.6052</td>\n",
       "      <td>6.5863</td>\n",
       "      <td>3.4751</td>\n",
       "      <td>0</td>\n",
       "      <td>4.4362</td>\n",
       "      <td>1.0578</td>\n",
       "      <td>1.7084</td>\n",
       "      <td>3.4935</td>\n",
       "      <td>1.5217</td>\n",
       "      <td>6.5522</td>\n",
       "      <td>3.1739</td>\n",
       "      <td>11.4502</td>\n",
       "      <td>3.8238</td>\n",
       "      <td>8.7218</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>2.5153</td>\n",
       "      <td>1.5217</td>\n",
       "      <td>1.5518</td>\n",
       "      <td>1.5776</td>\n",
       "      <td>1.2065</td>\n",
       "      <td>-1.1432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1967-02-23</th>\n",
       "      <td>4.6012</td>\n",
       "      <td>6.5774</td>\n",
       "      <td>3.4751</td>\n",
       "      <td>0</td>\n",
       "      <td>4.4362</td>\n",
       "      <td>1.0578</td>\n",
       "      <td>1.7084</td>\n",
       "      <td>3.4935</td>\n",
       "      <td>1.5217</td>\n",
       "      <td>6.5522</td>\n",
       "      <td>3.1739</td>\n",
       "      <td>11.4502</td>\n",
       "      <td>3.8238</td>\n",
       "      <td>8.7218</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>2.5153</td>\n",
       "      <td>1.5217</td>\n",
       "      <td>1.5518</td>\n",
       "      <td>1.5776</td>\n",
       "      <td>1.2065</td>\n",
       "      <td>-1.1432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1967-03-02</th>\n",
       "      <td>4.6032</td>\n",
       "      <td>6.5820</td>\n",
       "      <td>3.4751</td>\n",
       "      <td>0</td>\n",
       "      <td>4.4700</td>\n",
       "      <td>1.0613</td>\n",
       "      <td>1.7011</td>\n",
       "      <td>3.4935</td>\n",
       "      <td>1.5326</td>\n",
       "      <td>6.5860</td>\n",
       "      <td>3.1772</td>\n",
       "      <td>11.4869</td>\n",
       "      <td>3.8177</td>\n",
       "      <td>8.7185</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>2.5153</td>\n",
       "      <td>1.5326</td>\n",
       "      <td>1.5173</td>\n",
       "      <td>1.5427</td>\n",
       "      <td>1.2692</td>\n",
       "      <td>-1.2586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1967-03-09</th>\n",
       "      <td>4.6042</td>\n",
       "      <td>6.5852</td>\n",
       "      <td>3.4751</td>\n",
       "      <td>0</td>\n",
       "      <td>4.4700</td>\n",
       "      <td>1.0613</td>\n",
       "      <td>1.7011</td>\n",
       "      <td>3.4935</td>\n",
       "      <td>1.5326</td>\n",
       "      <td>6.5860</td>\n",
       "      <td>3.1772</td>\n",
       "      <td>11.4869</td>\n",
       "      <td>3.8177</td>\n",
       "      <td>8.7185</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>2.5153</td>\n",
       "      <td>1.5326</td>\n",
       "      <td>1.5173</td>\n",
       "      <td>1.5427</td>\n",
       "      <td>1.2692</td>\n",
       "      <td>-1.2586</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              BCI   BCIp   BCIg  USRECD  IE_SP_Comp  IE_SP_Dividend  IE_SP_Earnings  IE_Consumer_CPI  IE_Long_Interest  IE_Real_Price  IE_Real_Dividend  IE_Return_Price  IE_Real_Earnings  \\\n",
       "Date                                                                                                                                                                                         \n",
       "1967-02-09 4.6052 6.5870 3.4751       0      4.4362          1.0578          1.7084           3.4935            1.5217         6.5522            3.1739          11.4502            3.8238   \n",
       "1967-02-16 4.6052 6.5863 3.4751       0      4.4362          1.0578          1.7084           3.4935            1.5217         6.5522            3.1739          11.4502            3.8238   \n",
       "1967-02-23 4.6012 6.5774 3.4751       0      4.4362          1.0578          1.7084           3.4935            1.5217         6.5522            3.1739          11.4502            3.8238   \n",
       "1967-03-02 4.6032 6.5820 3.4751       0      4.4700          1.0613          1.7011           3.4935            1.5326         6.5860            3.1772          11.4869            3.8177   \n",
       "1967-03-09 4.6042 6.5852 3.4751       0      4.4700          1.0613          1.7011           3.4935            1.5326         6.5860            3.1772          11.4869            3.8177   \n",
       "\n",
       "            IE_Scaled_Earnings  IE_Monthly_Returns  IE_Real_Returns  YC_10_Year  YC_3_Month  YC_3_Month_Bond  YC_Spread  YC_Rec_Prob  \n",
       "Date                                                                                                                                  \n",
       "1967-02-09              8.7218              0.0000           2.5153      1.5217      1.5518           1.5776     1.2065      -1.1432  \n",
       "1967-02-16              8.7218              0.0000           2.5153      1.5217      1.5518           1.5776     1.2065      -1.1432  \n",
       "1967-02-23              8.7218              0.0000           2.5153      1.5217      1.5518           1.5776     1.2065      -1.1432  \n",
       "1967-03-02              8.7185              0.0100           2.5153      1.5326      1.5173           1.5427     1.2692      -1.2586  \n",
       "1967-03-09              8.7185              0.0100           2.5153      1.5326      1.5173           1.5427     1.2692      -1.2586  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the data and do a little bit of wrangling:\n",
    "df = pd.read_csv(df_path)\n",
    "df.Date = pd.to_datetime(df.Date)\n",
    "df = df.set_index(\"Date\", drop=True)\n",
    "df = df.drop(columns=\"Unnamed: 0\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into training and test sets and hold out the test set until the end, so that it remains \"unseen\".\n",
    "lag_of_y = 21 # This is the lag we introduce to the target variable so that we assess the indicator's \n",
    "              # ability to predict the target variable this many steps into the future.\n",
    "              # With BCI, a lag of 21 data points corresponds to about half a year.\n",
    "\n",
    "X_train, y_train = df.iloc[:-lag_of_y, df.columns != \"USRECD\"], df.iloc[lag_of_y:, df.columns == \"USRECD\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for feature in features:\n",
    "#     plt.figure()\n",
    "#     X_train[feature].hist(bins = 50)\n",
    "#     plt.xlabel(feature,fontsize=15)\n",
    "#     plt.ylabel(\"Frequency\",fontsize=15)\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29 ... 529 530 531 532 533\n",
      " 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550 551\n",
      " 552 553 554 555 556 557 558] TEST: [ 559  560  561  562  563  564  565  566  567  568  569  570  571  572\n",
      "  573  574  575  576  577  578  579  580  581  582  583  584  585  586\n",
      "  587  588 ... 1084 1085 1086 1087 1088 1089 1090 1091 1092 1093 1094 1095\n",
      " 1096 1097 1098 1099 1100 1101 1102 1103 1104 1105 1106 1107 1108 1109\n",
      " 1110 1111 1112 1113]\n",
      "TRAIN: [   0    1    2    3    4    5    6    7    8    9   10   11   12   13\n",
      "   14   15   16   17   18   19   20   21   22   23   24   25   26   27\n",
      "   28   29 ... 1084 1085 1086 1087 1088 1089 1090 1091 1092 1093 1094 1095\n",
      " 1096 1097 1098 1099 1100 1101 1102 1103 1104 1105 1106 1107 1108 1109\n",
      " 1110 1111 1112 1113] TEST: [1114 1115 1116 1117 1118 1119 1120 1121 1122 1123 1124 1125 1126 1127\n",
      " 1128 1129 1130 1131 1132 1133 1134 1135 1136 1137 1138 1139 1140 1141\n",
      " 1142 1143 ... 1639 1640 1641 1642 1643 1644 1645 1646 1647 1648 1649 1650\n",
      " 1651 1652 1653 1654 1655 1656 1657 1658 1659 1660 1661 1662 1663 1664\n",
      " 1665 1666 1667 1668]\n",
      "TRAIN: [   0    1    2    3    4    5    6    7    8    9   10   11   12   13\n",
      "   14   15   16   17   18   19   20   21   22   23   24   25   26   27\n",
      "   28   29 ... 1639 1640 1641 1642 1643 1644 1645 1646 1647 1648 1649 1650\n",
      " 1651 1652 1653 1654 1655 1656 1657 1658 1659 1660 1661 1662 1663 1664\n",
      " 1665 1666 1667 1668] TEST: [1669 1670 1671 1672 1673 1674 1675 1676 1677 1678 1679 1680 1681 1682\n",
      " 1683 1684 1685 1686 1687 1688 1689 1690 1691 1692 1693 1694 1695 1696\n",
      " 1697 1698 ... 2194 2195 2196 2197 2198 2199 2200 2201 2202 2203 2204 2205\n",
      " 2206 2207 2208 2209 2210 2211 2212 2213 2214 2215 2216 2217 2218 2219\n",
      " 2220 2221 2222 2223]\n",
      "TRAIN: [   0    1    2    3    4    5    6    7    8    9   10   11   12   13\n",
      "   14   15   16   17   18   19   20   21   22   23   24   25   26   27\n",
      "   28   29 ... 2194 2195 2196 2197 2198 2199 2200 2201 2202 2203 2204 2205\n",
      " 2206 2207 2208 2209 2210 2211 2212 2213 2214 2215 2216 2217 2218 2219\n",
      " 2220 2221 2222 2223] TEST: [2224 2225 2226 2227 2228 2229 2230 2231 2232 2233 2234 2235 2236 2237\n",
      " 2238 2239 2240 2241 2242 2243 2244 2245 2246 2247 2248 2249 2250 2251\n",
      " 2252 2253 ... 2749 2750 2751 2752 2753 2754 2755 2756 2757 2758 2759 2760\n",
      " 2761 2762 2763 2764 2765 2766 2767 2768 2769 2770 2771 2772 2773 2774\n",
      " 2775 2776 2777 2778]\n"
     ]
    }
   ],
   "source": [
    "# Do a time series cross-validation on the test set by splitting it to k folds and doing a \"rolling\"\n",
    "# validation against a validation fold, then averaging out the metrics.\n",
    "splits = 4 # This is the number of splits/folds in the rolling validation.\n",
    "tscv = TimeSeriesSplit(n_splits=splits)\n",
    "\n",
    "for train_index, test_index in tscv.split(X_train): # Rolling cross-validation happens inside this loop.\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression\n",
      "0.9167965471765975 0.40074906367041196\n",
      "0.862124248496994 0.9344569288389513\n",
      "0.6414773085573751 0.8295880149812734\n",
      "0.9867924528301887 0.7677902621722846\n",
      "Penalized SVM\n",
      "0.8052391799544419 0.25842696629213485\n",
      "0.6703693100486687 0.9344569288389513\n",
      "0.6364324301599648 0.799625468164794\n",
      "0.965566037735849 0.7340823970037453\n",
      "Random Forest\n",
      "0.5407984654118211 0.7902621722846442\n",
      "0.5732035499570569 0.7659176029962547\n",
      "0.9051247556387026 0.8014981273408239\n",
      "0.9570754716981131 0.3352059925093633\n"
     ]
    }
   ],
   "source": [
    "AUC_ROCs = dict()\n",
    "ACCs = dict()\n",
    "for model_name, get_model in zip(model_names, get_models):\n",
    "    print(model_name)\n",
    "    AUC_ROCs[model_name] = 0\n",
    "    ACCs[model_name] = 0\n",
    "    for train_index, test_index in tscv.split(X_train): # Rolling cross-validation happens inside this loop.\n",
    "        X_train_fold, X_validation_fold = X_train.iloc[train_index[:-lag_of_y], X_train.columns != \"USRECD\"], \\\n",
    "            X_train.iloc[test_index[:-lag_of_y], X_train.columns != \"USRECD\"]\n",
    "        y_train_fold, y_validation_fold = y_train.iloc[train_index[lag_of_y:], y_train.columns == \"USRECD\"], \\\n",
    "            y_train.iloc[test_index[lag_of_y:], y_train.columns == \"USRECD\"]\n",
    "            \n",
    "        scalers = dict()\n",
    "        for feature in features:\n",
    "            scalers[feature] = StandardScaler()\n",
    "            scalers[feature].fit(X_train_fold[[feature]])\n",
    "            X_train_fold[feature] = scalers[feature].transform(X_train_fold[[feature]])\n",
    "            X_validation_fold[feature] = scalers[feature].transform(X_validation_fold[[feature]])\n",
    "            \n",
    "        model = get_model()\n",
    "        model.fit(X_train_fold[features], y_train_fold[\"USRECD\"])\n",
    "        positive_probs = [p[1] for p in model.predict_proba(X_validation_fold[features])]\n",
    "        AUC_ROC = metrics.roc_auc_score(y_validation_fold, positive_probs)\n",
    "        AUC_ROCs[model_name] += AUC_ROC\n",
    "        predictions = model.predict(X_validation_fold[features])\n",
    "        ACC = accuracy_score(y_validation_fold, predictions)\n",
    "        ACCs[model_name] += ACC\n",
    "        print(AUC_ROC, ACC)\n",
    "        \n",
    "    AUC_ROCs[model_name] /= splits\n",
    "    ACCs[model_name] /= splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression\n",
      "AUC ROC: 0.8517976392652888\n",
      "accuracy: 0.7331460674157303\n",
      "Penalized SVM\n",
      "AUC ROC: 0.7694017394747311\n",
      "accuracy: 0.6816479400749064\n",
      "Random Forest\n",
      "AUC ROC: 0.7440505606764234\n",
      "accuracy: 0.6732209737827716\n"
     ]
    }
   ],
   "source": [
    "for model_name in model_names:\n",
    "    print(model_name)\n",
    "    print(f\"AUC ROC: {AUC_ROCs[model_name]}\")\n",
    "    print(f\"accuracy: {ACCs[model_name]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
