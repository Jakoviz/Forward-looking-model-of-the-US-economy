{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import figure\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import TimeSeriesSplit, train_test_split\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Settings:\n",
    "pd.set_option('display.width', 190)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 20)\n",
    "pd.set_option('max_colwidth', 200)\n",
    "pd.options.display.float_format = '{:.4f}'.format\n",
    "plt.style.use('default')\n",
    "np.set_printoptions(threshold = 30, edgeitems = 30, precision = 2, suppress = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_path = \"../merged_data/features_USRECD.csv\"\n",
    "features = [\"BCI\", \"BCIp\", \"BCIg\", 'IE_SP_Comp', 'IE_SP_Dividend', 'IE_SP_Earnings', 'IE_Consumer_CPI', 'IE_Long_Interest', 'IE_Real_Price', 'IE_Real_Dividend', 'IE_Return_Price', 'IE_Real_Earnings',\n",
    "                'IE_Scaled_Earnings', 'IE_Monthly_Returns', 'IE_Real_Returns', \"YC_10_Year\", \"YC_3_Month\", \"YC_3_Month_Bond\", \"YC_Spread\", \"YC_Rec_Prob\"]\n",
    "model_names = [\"Logistic Regression\", \"Penalized SVM\", \"Random Forest\"]\n",
    "get_models = [lambda: linear_model.LogisticRegression(), lambda: svm.SVC(kernel='linear', class_weight='balanced', probability=True), \n",
    "          lambda: RandomForestClassifier()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BCI</th>\n",
       "      <th>BCIp</th>\n",
       "      <th>BCIg</th>\n",
       "      <th>USRECD</th>\n",
       "      <th>IE_SP_Comp</th>\n",
       "      <th>IE_SP_Dividend</th>\n",
       "      <th>IE_SP_Earnings</th>\n",
       "      <th>IE_Consumer_CPI</th>\n",
       "      <th>IE_Long_Interest</th>\n",
       "      <th>IE_Real_Price</th>\n",
       "      <th>IE_Real_Dividend</th>\n",
       "      <th>IE_Return_Price</th>\n",
       "      <th>IE_Real_Earnings</th>\n",
       "      <th>IE_Scaled_Earnings</th>\n",
       "      <th>IE_Monthly_Returns</th>\n",
       "      <th>IE_Real_Returns</th>\n",
       "      <th>YC_10_Year</th>\n",
       "      <th>YC_3_Month</th>\n",
       "      <th>YC_3_Month_Bond</th>\n",
       "      <th>YC_Spread</th>\n",
       "      <th>YC_Rec_Prob</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1967-02-09</th>\n",
       "      <td>4.6052</td>\n",
       "      <td>6.5870</td>\n",
       "      <td>3.4751</td>\n",
       "      <td>0</td>\n",
       "      <td>4.4362</td>\n",
       "      <td>1.0578</td>\n",
       "      <td>1.7084</td>\n",
       "      <td>3.4935</td>\n",
       "      <td>1.5217</td>\n",
       "      <td>6.5522</td>\n",
       "      <td>3.1739</td>\n",
       "      <td>11.4502</td>\n",
       "      <td>3.8238</td>\n",
       "      <td>8.7218</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>2.5153</td>\n",
       "      <td>1.5217</td>\n",
       "      <td>1.5518</td>\n",
       "      <td>1.5776</td>\n",
       "      <td>1.2065</td>\n",
       "      <td>-1.1432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1967-02-16</th>\n",
       "      <td>4.6052</td>\n",
       "      <td>6.5863</td>\n",
       "      <td>3.4751</td>\n",
       "      <td>0</td>\n",
       "      <td>4.4362</td>\n",
       "      <td>1.0578</td>\n",
       "      <td>1.7084</td>\n",
       "      <td>3.4935</td>\n",
       "      <td>1.5217</td>\n",
       "      <td>6.5522</td>\n",
       "      <td>3.1739</td>\n",
       "      <td>11.4502</td>\n",
       "      <td>3.8238</td>\n",
       "      <td>8.7218</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>2.5153</td>\n",
       "      <td>1.5217</td>\n",
       "      <td>1.5518</td>\n",
       "      <td>1.5776</td>\n",
       "      <td>1.2065</td>\n",
       "      <td>-1.1432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1967-02-23</th>\n",
       "      <td>4.6012</td>\n",
       "      <td>6.5774</td>\n",
       "      <td>3.4751</td>\n",
       "      <td>0</td>\n",
       "      <td>4.4362</td>\n",
       "      <td>1.0578</td>\n",
       "      <td>1.7084</td>\n",
       "      <td>3.4935</td>\n",
       "      <td>1.5217</td>\n",
       "      <td>6.5522</td>\n",
       "      <td>3.1739</td>\n",
       "      <td>11.4502</td>\n",
       "      <td>3.8238</td>\n",
       "      <td>8.7218</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>2.5153</td>\n",
       "      <td>1.5217</td>\n",
       "      <td>1.5518</td>\n",
       "      <td>1.5776</td>\n",
       "      <td>1.2065</td>\n",
       "      <td>-1.1432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1967-03-02</th>\n",
       "      <td>4.6032</td>\n",
       "      <td>6.5820</td>\n",
       "      <td>3.4751</td>\n",
       "      <td>0</td>\n",
       "      <td>4.4700</td>\n",
       "      <td>1.0613</td>\n",
       "      <td>1.7011</td>\n",
       "      <td>3.4935</td>\n",
       "      <td>1.5326</td>\n",
       "      <td>6.5860</td>\n",
       "      <td>3.1772</td>\n",
       "      <td>11.4869</td>\n",
       "      <td>3.8177</td>\n",
       "      <td>8.7185</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>2.5153</td>\n",
       "      <td>1.5326</td>\n",
       "      <td>1.5173</td>\n",
       "      <td>1.5427</td>\n",
       "      <td>1.2692</td>\n",
       "      <td>-1.2586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1967-03-09</th>\n",
       "      <td>4.6042</td>\n",
       "      <td>6.5852</td>\n",
       "      <td>3.4751</td>\n",
       "      <td>0</td>\n",
       "      <td>4.4700</td>\n",
       "      <td>1.0613</td>\n",
       "      <td>1.7011</td>\n",
       "      <td>3.4935</td>\n",
       "      <td>1.5326</td>\n",
       "      <td>6.5860</td>\n",
       "      <td>3.1772</td>\n",
       "      <td>11.4869</td>\n",
       "      <td>3.8177</td>\n",
       "      <td>8.7185</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>2.5153</td>\n",
       "      <td>1.5326</td>\n",
       "      <td>1.5173</td>\n",
       "      <td>1.5427</td>\n",
       "      <td>1.2692</td>\n",
       "      <td>-1.2586</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              BCI   BCIp   BCIg  USRECD  IE_SP_Comp  IE_SP_Dividend  IE_SP_Earnings  IE_Consumer_CPI  IE_Long_Interest  IE_Real_Price  IE_Real_Dividend  IE_Return_Price  IE_Real_Earnings  \\\n",
       "Date                                                                                                                                                                                         \n",
       "1967-02-09 4.6052 6.5870 3.4751       0      4.4362          1.0578          1.7084           3.4935            1.5217         6.5522            3.1739          11.4502            3.8238   \n",
       "1967-02-16 4.6052 6.5863 3.4751       0      4.4362          1.0578          1.7084           3.4935            1.5217         6.5522            3.1739          11.4502            3.8238   \n",
       "1967-02-23 4.6012 6.5774 3.4751       0      4.4362          1.0578          1.7084           3.4935            1.5217         6.5522            3.1739          11.4502            3.8238   \n",
       "1967-03-02 4.6032 6.5820 3.4751       0      4.4700          1.0613          1.7011           3.4935            1.5326         6.5860            3.1772          11.4869            3.8177   \n",
       "1967-03-09 4.6042 6.5852 3.4751       0      4.4700          1.0613          1.7011           3.4935            1.5326         6.5860            3.1772          11.4869            3.8177   \n",
       "\n",
       "            IE_Scaled_Earnings  IE_Monthly_Returns  IE_Real_Returns  YC_10_Year  YC_3_Month  YC_3_Month_Bond  YC_Spread  YC_Rec_Prob  \n",
       "Date                                                                                                                                  \n",
       "1967-02-09              8.7218              0.0000           2.5153      1.5217      1.5518           1.5776     1.2065      -1.1432  \n",
       "1967-02-16              8.7218              0.0000           2.5153      1.5217      1.5518           1.5776     1.2065      -1.1432  \n",
       "1967-02-23              8.7218              0.0000           2.5153      1.5217      1.5518           1.5776     1.2065      -1.1432  \n",
       "1967-03-02              8.7185              0.0100           2.5153      1.5326      1.5173           1.5427     1.2692      -1.2586  \n",
       "1967-03-09              8.7185              0.0100           2.5153      1.5326      1.5173           1.5427     1.2692      -1.2586  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the data and do a little bit of wrangling:\n",
    "df = pd.read_csv(df_path)\n",
    "df.Date = pd.to_datetime(df.Date)\n",
    "df = df.set_index(\"Date\", drop=True)\n",
    "df = df.drop(columns=\"Unnamed: 0\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into training and test sets and hold out the test set until the end, so that it remains \"unseen\".\n",
    "lag_of_y = 21 # This is the lag we introduce to the target variable so that we assess the indicator's \n",
    "              # ability to predict the target variable this many steps into the future.\n",
    "              # With BCI, a lag of 21 data points corresponds to about half a year.\n",
    "        \n",
    "X_train, X_test, y_train, y_test = train_test_split(df.iloc[:-lag_of_y, df.columns != \"USRECD\"], \\\n",
    "    df.iloc[lag_of_y:, df.columns == \"USRECD\"], test_size=0.1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for feature in features:\n",
    "#     plt.figure()\n",
    "#     X_train[feature].hist(bins = 50)\n",
    "#     plt.xlabel(feature,fontsize=15)\n",
    "#     plt.ylabel(\"Frequency\",fontsize=15)\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29 ... 471 472 473 474 475\n",
      " 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493\n",
      " 494 495 496 497 498 499 500] TEST: [ 501  502  503  504  505  506  507  508  509  510  511  512  513  514\n",
      "  515  516  517  518  519  520  521  522  523  524  525  526  527  528\n",
      "  529  530 ...  971  972  973  974  975  976  977  978  979  980  981  982\n",
      "  983  984  985  986  987  988  989  990  991  992  993  994  995  996\n",
      "  997  998  999 1000]\n",
      "TRAIN: [   0    1    2    3    4    5    6    7    8    9   10   11   12   13\n",
      "   14   15   16   17   18   19   20   21   22   23   24   25   26   27\n",
      "   28   29 ...  971  972  973  974  975  976  977  978  979  980  981  982\n",
      "  983  984  985  986  987  988  989  990  991  992  993  994  995  996\n",
      "  997  998  999 1000] TEST: [1001 1002 1003 1004 1005 1006 1007 1008 1009 1010 1011 1012 1013 1014\n",
      " 1015 1016 1017 1018 1019 1020 1021 1022 1023 1024 1025 1026 1027 1028\n",
      " 1029 1030 ... 1471 1472 1473 1474 1475 1476 1477 1478 1479 1480 1481 1482\n",
      " 1483 1484 1485 1486 1487 1488 1489 1490 1491 1492 1493 1494 1495 1496\n",
      " 1497 1498 1499 1500]\n",
      "TRAIN: [   0    1    2    3    4    5    6    7    8    9   10   11   12   13\n",
      "   14   15   16   17   18   19   20   21   22   23   24   25   26   27\n",
      "   28   29 ... 1471 1472 1473 1474 1475 1476 1477 1478 1479 1480 1481 1482\n",
      " 1483 1484 1485 1486 1487 1488 1489 1490 1491 1492 1493 1494 1495 1496\n",
      " 1497 1498 1499 1500] TEST: [1501 1502 1503 1504 1505 1506 1507 1508 1509 1510 1511 1512 1513 1514\n",
      " 1515 1516 1517 1518 1519 1520 1521 1522 1523 1524 1525 1526 1527 1528\n",
      " 1529 1530 ... 1971 1972 1973 1974 1975 1976 1977 1978 1979 1980 1981 1982\n",
      " 1983 1984 1985 1986 1987 1988 1989 1990 1991 1992 1993 1994 1995 1996\n",
      " 1997 1998 1999 2000]\n",
      "TRAIN: [   0    1    2    3    4    5    6    7    8    9   10   11   12   13\n",
      "   14   15   16   17   18   19   20   21   22   23   24   25   26   27\n",
      "   28   29 ... 1971 1972 1973 1974 1975 1976 1977 1978 1979 1980 1981 1982\n",
      " 1983 1984 1985 1986 1987 1988 1989 1990 1991 1992 1993 1994 1995 1996\n",
      " 1997 1998 1999 2000] TEST: [2001 2002 2003 2004 2005 2006 2007 2008 2009 2010 2011 2012 2013 2014\n",
      " 2015 2016 2017 2018 2019 2020 2021 2022 2023 2024 2025 2026 2027 2028\n",
      " 2029 2030 ... 2471 2472 2473 2474 2475 2476 2477 2478 2479 2480 2481 2482\n",
      " 2483 2484 2485 2486 2487 2488 2489 2490 2491 2492 2493 2494 2495 2496\n",
      " 2497 2498 2499 2500]\n"
     ]
    }
   ],
   "source": [
    "# Do a time series cross-validation on the test set by splitting it to k folds and doing a \"rolling\"\n",
    "# validation against a validation fold, then averaging out the metrics.\n",
    "splits = 4 # This is the number of splits/folds in the rolling validation.\n",
    "tscv = TimeSeriesSplit(n_splits=splits)\n",
    "\n",
    "for train_index, test_index in tscv.split(X_train): # Rolling cross-validation happens inside this loop.\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression\n",
      "0.8996436403508772 0.4112734864300626\n",
      "0.7099099099099099 0.9269311064718163\n",
      "0.995045045045045 0.7014613778705637\n",
      "0.8209923908178272 0.837160751565762\n",
      "Penalized SVM\n",
      "0.7395833333333333 0.302713987473904\n",
      "0.806048906048906 0.9269311064718163\n",
      "0.978957528957529 0.46346555323590816\n",
      "0.6914764371123473 0.837160751565762\n",
      "Random Forest\n",
      "0.6559347587719297 0.8016701461377871\n",
      "0.8904118404118404 0.8872651356993737\n",
      "0.98005148005148 0.9478079331941545\n",
      "0.82118421893983 0.8392484342379958\n"
     ]
    }
   ],
   "source": [
    "AUC_ROCs = dict()\n",
    "ACCs = dict()\n",
    "for model_name, get_model in zip(model_names, get_models):\n",
    "    print(model_name)\n",
    "    AUC_ROCs[model_name] = 0\n",
    "    ACCs[model_name] = 0\n",
    "    for train_index, test_index in tscv.split(X_train): # Rolling cross-validation happens inside this loop.\n",
    "        X_train_fold, X_validation_fold = X_train.iloc[train_index[:-lag_of_y], X_train.columns != \"USRECD\"], \\\n",
    "            X_train.iloc[test_index[:-lag_of_y], X_train.columns != \"USRECD\"]\n",
    "        y_train_fold, y_validation_fold = y_train.iloc[train_index[lag_of_y:], y_train.columns == \"USRECD\"], \\\n",
    "            y_train.iloc[test_index[lag_of_y:], y_train.columns == \"USRECD\"]\n",
    "            \n",
    "        scalers = dict()\n",
    "        for feature in features:\n",
    "            scalers[feature] = StandardScaler()\n",
    "            scalers[feature].fit(X_train_fold[[feature]])\n",
    "            X_train_fold[feature] = scalers[feature].transform(X_train_fold[[feature]])\n",
    "            X_validation_fold[feature] = scalers[feature].transform(X_validation_fold[[feature]])\n",
    "            \n",
    "        model = get_model()\n",
    "        model.fit(X_train_fold[features], y_train_fold[\"USRECD\"])\n",
    "        positive_probs = [p[1] for p in model.predict_proba(X_validation_fold[features])]\n",
    "        AUC_ROC = metrics.roc_auc_score(y_validation_fold, positive_probs)\n",
    "        AUC_ROCs[model_name] += AUC_ROC\n",
    "        predictions = model.predict(X_validation_fold[features])\n",
    "        ACC = accuracy_score(y_validation_fold, predictions)\n",
    "        ACCs[model_name] += ACC\n",
    "        print(AUC_ROC, ACC)\n",
    "        \n",
    "    AUC_ROCs[model_name] /= splits\n",
    "    ACCs[model_name] /= splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression\n",
      "AUC ROC: 0.8563977465309149\n",
      "accuracy: 0.7192066805845512\n",
      "Penalized SVM\n",
      "AUC ROC: 0.804016551363029\n",
      "accuracy: 0.6325678496868476\n",
      "Random Forest\n",
      "AUC ROC: 0.8368955745437701\n",
      "accuracy: 0.8689979123173278\n"
     ]
    }
   ],
   "source": [
    "for model_name in model_names:\n",
    "    print(model_name)\n",
    "    print(f\"AUC ROC: {AUC_ROCs[model_name]}\")\n",
    "    print(f\"accuracy: {ACCs[model_name]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5, 0.8560575769692124)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# random guess\n",
    "total = y_train.shape[0]\n",
    "metrics.roc_auc_score(y_train.USRECD, np.zeros(total)), accuracy_score(y_train.USRECD, np.zeros(total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "USRECD\n",
       "0         274\n",
       "1           4\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.copy()\n",
    "X_test = X_test.copy()\n",
    "\n",
    "all_scalers = dict()\n",
    "for feature in features:\n",
    "    all_scalers[feature] = StandardScaler()\n",
    "    all_scalers[feature].fit(X_train[[feature]])\n",
    "    X_train[feature] = all_scalers[feature].transform(X_train[[feature]])\n",
    "    X_test[feature] = all_scalers[feature].transform(X_test[[feature]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.8]\n",
      "[6.44]\n",
      "[3.61]\n",
      "[5.88]\n",
      "[2.29]\n",
      "[3.06]\n",
      "[4.71]\n",
      "[1.81]\n",
      "[6.78]\n",
      "[3.18]\n",
      "[12.51]\n",
      "[3.96]\n",
      "[9.69]\n",
      "[0.01]\n",
      "[2.96]\n",
      "[1.81]\n",
      "[1.07]\n",
      "[1.1]\n",
      "[1.57]\n",
      "[-2.89]\n"
     ]
    }
   ],
   "source": [
    "for feature in features:\n",
    "    print(all_scalers[feature].mean_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression\n",
      "0.6541970802919709\n",
      "0.7661870503597122\n",
      "Penalized SVM\n",
      "0.7901459854014597\n",
      "0.7877697841726619\n",
      "Random Forest\n",
      "0.9260948905109488\n",
      "0.9856115107913669\n"
     ]
    }
   ],
   "source": [
    "for model_name, get_model in zip(model_names, get_models):\n",
    "    print(model_name)\n",
    "    model = get_model()\n",
    "    model.fit(X_train[features], y_train[\"USRECD\"])\n",
    "    positive_probs = [p[1] for p in model.predict_proba(X_test[features])]\n",
    "    AUC_ROC = metrics.roc_auc_score(y_test, positive_probs)\n",
    "    print(AUC_ROC)\n",
    "    predictions = model.predict(X_test[features])\n",
    "    ACC = accuracy_score(y_test, predictions)\n",
    "    print(ACC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
