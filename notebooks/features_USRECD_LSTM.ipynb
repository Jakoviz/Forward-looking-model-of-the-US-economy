{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import figure\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import TimeSeriesSplit, train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "References:\n",
    "1. https://machinelearningmastery.com/how-to-develop-lstm-models-for-time-series-forecasting/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Settings:\n",
    "pd.set_option('display.width', 190)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 20)\n",
    "pd.set_option('max_colwidth', 200)\n",
    "pd.options.display.float_format = '{:.4f}'.format\n",
    "plt.style.use('default')\n",
    "np.set_printoptions(threshold = 30, edgeitems = 30, precision = 2, suppress = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_sequences(Xs, ys, n_steps):\n",
    "    X, y = list(), list()\n",
    "    for i in range(len(ys)):\n",
    "        # find the end of this pattern\n",
    "        end_ix = i + n_steps\n",
    "        # check if we are beyond the dataset\n",
    "        if end_ix > len(ys):\n",
    "            break\n",
    "        # gather input and output parts of the pattern\n",
    "        seq_x, seq_y = Xs[i: end_ix], ys[end_ix - 1]\n",
    "        X.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "    return np.array(X), np.array(y).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam\n",
    "from skorch import NeuralNetBinaryClassifier\n",
    "\n",
    "\n",
    "class MyModule(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyModule, self).__init__()\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size=20, hidden_size=10, num_layers=1, batch_first=True)\n",
    "        self.dense = nn.Linear(10, 1)\n",
    "\n",
    "    def forward(self, X, **kwargs):\n",
    "        output, hidden = self.lstm(X)\n",
    "        X = self.dense(output[:, -1, :])\n",
    "        return X\n",
    "\n",
    "def get_model():\n",
    "    model = NeuralNetBinaryClassifier(\n",
    "        MyModule,\n",
    "        optimizer=Adam,\n",
    "        max_epochs=50,\n",
    "        lr=3e-4,\n",
    "        batch_size=16,\n",
    "        iterator_train__shuffle=True,\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_path = \"../merged_data/features_USRECD.csv\"\n",
    "features = [\"BCI\", \"BCIp\", \"BCIg\", 'IE_SP_Comp', 'IE_SP_Dividend', 'IE_SP_Earnings', 'IE_Consumer_CPI', 'IE_Long_Interest', 'IE_Real_Price', 'IE_Real_Dividend', 'IE_Return_Price', 'IE_Real_Earnings',\n",
    "                'IE_Scaled_Earnings', 'IE_Monthly_Returns', 'IE_Real_Returns', \"YC_10_Year\", \"YC_3_Month\", \"YC_3_Month_Bond\", \"YC_Spread\", \"YC_Rec_Prob\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BCI</th>\n",
       "      <th>BCIp</th>\n",
       "      <th>BCIg</th>\n",
       "      <th>USRECD</th>\n",
       "      <th>IE_SP_Comp</th>\n",
       "      <th>IE_SP_Dividend</th>\n",
       "      <th>IE_SP_Earnings</th>\n",
       "      <th>IE_Consumer_CPI</th>\n",
       "      <th>IE_Long_Interest</th>\n",
       "      <th>IE_Real_Price</th>\n",
       "      <th>IE_Real_Dividend</th>\n",
       "      <th>IE_Return_Price</th>\n",
       "      <th>IE_Real_Earnings</th>\n",
       "      <th>IE_Scaled_Earnings</th>\n",
       "      <th>IE_Monthly_Returns</th>\n",
       "      <th>IE_Real_Returns</th>\n",
       "      <th>YC_10_Year</th>\n",
       "      <th>YC_3_Month</th>\n",
       "      <th>YC_3_Month_Bond</th>\n",
       "      <th>YC_Spread</th>\n",
       "      <th>YC_Rec_Prob</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1967-02-09</th>\n",
       "      <td>4.6052</td>\n",
       "      <td>6.5870</td>\n",
       "      <td>3.4751</td>\n",
       "      <td>0</td>\n",
       "      <td>4.4362</td>\n",
       "      <td>1.0578</td>\n",
       "      <td>1.7084</td>\n",
       "      <td>3.4935</td>\n",
       "      <td>1.5217</td>\n",
       "      <td>6.5522</td>\n",
       "      <td>3.1739</td>\n",
       "      <td>11.4502</td>\n",
       "      <td>3.8238</td>\n",
       "      <td>8.7218</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>2.5153</td>\n",
       "      <td>1.5217</td>\n",
       "      <td>1.5518</td>\n",
       "      <td>1.5776</td>\n",
       "      <td>1.2065</td>\n",
       "      <td>-1.1432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1967-02-16</th>\n",
       "      <td>4.6052</td>\n",
       "      <td>6.5863</td>\n",
       "      <td>3.4751</td>\n",
       "      <td>0</td>\n",
       "      <td>4.4362</td>\n",
       "      <td>1.0578</td>\n",
       "      <td>1.7084</td>\n",
       "      <td>3.4935</td>\n",
       "      <td>1.5217</td>\n",
       "      <td>6.5522</td>\n",
       "      <td>3.1739</td>\n",
       "      <td>11.4502</td>\n",
       "      <td>3.8238</td>\n",
       "      <td>8.7218</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>2.5153</td>\n",
       "      <td>1.5217</td>\n",
       "      <td>1.5518</td>\n",
       "      <td>1.5776</td>\n",
       "      <td>1.2065</td>\n",
       "      <td>-1.1432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1967-02-23</th>\n",
       "      <td>4.6012</td>\n",
       "      <td>6.5774</td>\n",
       "      <td>3.4751</td>\n",
       "      <td>0</td>\n",
       "      <td>4.4362</td>\n",
       "      <td>1.0578</td>\n",
       "      <td>1.7084</td>\n",
       "      <td>3.4935</td>\n",
       "      <td>1.5217</td>\n",
       "      <td>6.5522</td>\n",
       "      <td>3.1739</td>\n",
       "      <td>11.4502</td>\n",
       "      <td>3.8238</td>\n",
       "      <td>8.7218</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>2.5153</td>\n",
       "      <td>1.5217</td>\n",
       "      <td>1.5518</td>\n",
       "      <td>1.5776</td>\n",
       "      <td>1.2065</td>\n",
       "      <td>-1.1432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1967-03-02</th>\n",
       "      <td>4.6032</td>\n",
       "      <td>6.5820</td>\n",
       "      <td>3.4751</td>\n",
       "      <td>0</td>\n",
       "      <td>4.4700</td>\n",
       "      <td>1.0613</td>\n",
       "      <td>1.7011</td>\n",
       "      <td>3.4935</td>\n",
       "      <td>1.5326</td>\n",
       "      <td>6.5860</td>\n",
       "      <td>3.1772</td>\n",
       "      <td>11.4869</td>\n",
       "      <td>3.8177</td>\n",
       "      <td>8.7185</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>2.5153</td>\n",
       "      <td>1.5326</td>\n",
       "      <td>1.5173</td>\n",
       "      <td>1.5427</td>\n",
       "      <td>1.2692</td>\n",
       "      <td>-1.2586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1967-03-09</th>\n",
       "      <td>4.6042</td>\n",
       "      <td>6.5852</td>\n",
       "      <td>3.4751</td>\n",
       "      <td>0</td>\n",
       "      <td>4.4700</td>\n",
       "      <td>1.0613</td>\n",
       "      <td>1.7011</td>\n",
       "      <td>3.4935</td>\n",
       "      <td>1.5326</td>\n",
       "      <td>6.5860</td>\n",
       "      <td>3.1772</td>\n",
       "      <td>11.4869</td>\n",
       "      <td>3.8177</td>\n",
       "      <td>8.7185</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>2.5153</td>\n",
       "      <td>1.5326</td>\n",
       "      <td>1.5173</td>\n",
       "      <td>1.5427</td>\n",
       "      <td>1.2692</td>\n",
       "      <td>-1.2586</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              BCI   BCIp   BCIg  USRECD  IE_SP_Comp  IE_SP_Dividend  IE_SP_Earnings  IE_Consumer_CPI  IE_Long_Interest  IE_Real_Price  IE_Real_Dividend  IE_Return_Price  IE_Real_Earnings  \\\n",
       "Date                                                                                                                                                                                         \n",
       "1967-02-09 4.6052 6.5870 3.4751       0      4.4362          1.0578          1.7084           3.4935            1.5217         6.5522            3.1739          11.4502            3.8238   \n",
       "1967-02-16 4.6052 6.5863 3.4751       0      4.4362          1.0578          1.7084           3.4935            1.5217         6.5522            3.1739          11.4502            3.8238   \n",
       "1967-02-23 4.6012 6.5774 3.4751       0      4.4362          1.0578          1.7084           3.4935            1.5217         6.5522            3.1739          11.4502            3.8238   \n",
       "1967-03-02 4.6032 6.5820 3.4751       0      4.4700          1.0613          1.7011           3.4935            1.5326         6.5860            3.1772          11.4869            3.8177   \n",
       "1967-03-09 4.6042 6.5852 3.4751       0      4.4700          1.0613          1.7011           3.4935            1.5326         6.5860            3.1772          11.4869            3.8177   \n",
       "\n",
       "            IE_Scaled_Earnings  IE_Monthly_Returns  IE_Real_Returns  YC_10_Year  YC_3_Month  YC_3_Month_Bond  YC_Spread  YC_Rec_Prob  \n",
       "Date                                                                                                                                  \n",
       "1967-02-09              8.7218              0.0000           2.5153      1.5217      1.5518           1.5776     1.2065      -1.1432  \n",
       "1967-02-16              8.7218              0.0000           2.5153      1.5217      1.5518           1.5776     1.2065      -1.1432  \n",
       "1967-02-23              8.7218              0.0000           2.5153      1.5217      1.5518           1.5776     1.2065      -1.1432  \n",
       "1967-03-02              8.7185              0.0100           2.5153      1.5326      1.5173           1.5427     1.2692      -1.2586  \n",
       "1967-03-09              8.7185              0.0100           2.5153      1.5326      1.5173           1.5427     1.2692      -1.2586  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the data and do a little bit of wrangling:\n",
    "df = pd.read_csv(df_path)\n",
    "df.Date = pd.to_datetime(df.Date)\n",
    "df = df.set_index(\"Date\", drop=True)\n",
    "df = df.drop(columns=\"Unnamed: 0\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into training and test sets and hold out the test set until the end, so that it remains \"unseen\".\n",
    "lag_of_y = 21 # This is the lag we introduce to the target variable so that we assess the indicator's \n",
    "              # ability to predict the target variable this many steps into the future.\n",
    "              # With BCI, a lag of 21 data points corresponds to about half a year.\n",
    "        \n",
    "X_train, y_train = df.iloc[:-lag_of_y, df.columns != \"USRECD\"], df.iloc[lag_of_y:, df.columns == \"USRECD\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29 ... 529 530 531 532 533\n",
      " 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550 551\n",
      " 552 553 554 555 556 557 558] TEST: [ 559  560  561  562  563  564  565  566  567  568  569  570  571  572\n",
      "  573  574  575  576  577  578  579  580  581  582  583  584  585  586\n",
      "  587  588 ... 1084 1085 1086 1087 1088 1089 1090 1091 1092 1093 1094 1095\n",
      " 1096 1097 1098 1099 1100 1101 1102 1103 1104 1105 1106 1107 1108 1109\n",
      " 1110 1111 1112 1113]\n",
      "TRAIN: [   0    1    2    3    4    5    6    7    8    9   10   11   12   13\n",
      "   14   15   16   17   18   19   20   21   22   23   24   25   26   27\n",
      "   28   29 ... 1084 1085 1086 1087 1088 1089 1090 1091 1092 1093 1094 1095\n",
      " 1096 1097 1098 1099 1100 1101 1102 1103 1104 1105 1106 1107 1108 1109\n",
      " 1110 1111 1112 1113] TEST: [1114 1115 1116 1117 1118 1119 1120 1121 1122 1123 1124 1125 1126 1127\n",
      " 1128 1129 1130 1131 1132 1133 1134 1135 1136 1137 1138 1139 1140 1141\n",
      " 1142 1143 ... 1639 1640 1641 1642 1643 1644 1645 1646 1647 1648 1649 1650\n",
      " 1651 1652 1653 1654 1655 1656 1657 1658 1659 1660 1661 1662 1663 1664\n",
      " 1665 1666 1667 1668]\n",
      "TRAIN: [   0    1    2    3    4    5    6    7    8    9   10   11   12   13\n",
      "   14   15   16   17   18   19   20   21   22   23   24   25   26   27\n",
      "   28   29 ... 1639 1640 1641 1642 1643 1644 1645 1646 1647 1648 1649 1650\n",
      " 1651 1652 1653 1654 1655 1656 1657 1658 1659 1660 1661 1662 1663 1664\n",
      " 1665 1666 1667 1668] TEST: [1669 1670 1671 1672 1673 1674 1675 1676 1677 1678 1679 1680 1681 1682\n",
      " 1683 1684 1685 1686 1687 1688 1689 1690 1691 1692 1693 1694 1695 1696\n",
      " 1697 1698 ... 2194 2195 2196 2197 2198 2199 2200 2201 2202 2203 2204 2205\n",
      " 2206 2207 2208 2209 2210 2211 2212 2213 2214 2215 2216 2217 2218 2219\n",
      " 2220 2221 2222 2223]\n",
      "TRAIN: [   0    1    2    3    4    5    6    7    8    9   10   11   12   13\n",
      "   14   15   16   17   18   19   20   21   22   23   24   25   26   27\n",
      "   28   29 ... 2194 2195 2196 2197 2198 2199 2200 2201 2202 2203 2204 2205\n",
      " 2206 2207 2208 2209 2210 2211 2212 2213 2214 2215 2216 2217 2218 2219\n",
      " 2220 2221 2222 2223] TEST: [2224 2225 2226 2227 2228 2229 2230 2231 2232 2233 2234 2235 2236 2237\n",
      " 2238 2239 2240 2241 2242 2243 2244 2245 2246 2247 2248 2249 2250 2251\n",
      " 2252 2253 ... 2749 2750 2751 2752 2753 2754 2755 2756 2757 2758 2759 2760\n",
      " 2761 2762 2763 2764 2765 2766 2767 2768 2769 2770 2771 2772 2773 2774\n",
      " 2775 2776 2777 2778]\n"
     ]
    }
   ],
   "source": [
    "# Do a time series cross-validation on the test set by splitting it to k folds and doing a \"rolling\"\n",
    "# validation against a validation fold, then averaging out the metrics.\n",
    "splits = 4 # This is the number of splits/folds in the rolling validation.\n",
    "tscv = TimeSeriesSplit(n_splits=splits)\n",
    "\n",
    "for train_index, test_index in tscv.split(X_train): # Rolling cross-validation happens inside this loop.\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7090\u001b[0m       \u001b[32m0.2075\u001b[0m        \u001b[35m0.7411\u001b[0m  0.0318\n",
      "      2        \u001b[36m0.6799\u001b[0m       \u001b[32m0.2453\u001b[0m        \u001b[35m0.7228\u001b[0m  0.0296\n",
      "      3        \u001b[36m0.6510\u001b[0m       \u001b[32m0.4340\u001b[0m        \u001b[35m0.7033\u001b[0m  0.0293\n",
      "      4        \u001b[36m0.6212\u001b[0m       \u001b[32m0.5660\u001b[0m        \u001b[35m0.6899\u001b[0m  0.0286\n",
      "      5        \u001b[36m0.5918\u001b[0m       \u001b[32m0.6038\u001b[0m        \u001b[35m0.6708\u001b[0m  0.0289\n",
      "      6        \u001b[36m0.5622\u001b[0m       \u001b[32m0.6604\u001b[0m        \u001b[35m0.6552\u001b[0m  0.0296\n",
      "      7        \u001b[36m0.5336\u001b[0m       \u001b[32m0.6981\u001b[0m        \u001b[35m0.6373\u001b[0m  0.0294\n",
      "      8        \u001b[36m0.5051\u001b[0m       \u001b[32m0.7358\u001b[0m        \u001b[35m0.6205\u001b[0m  0.0290\n",
      "      9        \u001b[36m0.4777\u001b[0m       \u001b[32m0.7736\u001b[0m        \u001b[35m0.6032\u001b[0m  0.0296\n",
      "     10        \u001b[36m0.4514\u001b[0m       0.7642        \u001b[35m0.5867\u001b[0m  0.0290\n",
      "     11        \u001b[36m0.4264\u001b[0m       \u001b[32m0.8019\u001b[0m        \u001b[35m0.5726\u001b[0m  0.0280\n",
      "     12        \u001b[36m0.4028\u001b[0m       0.7925        \u001b[35m0.5590\u001b[0m  0.0279\n",
      "     13        \u001b[36m0.3804\u001b[0m       0.7925        \u001b[35m0.5449\u001b[0m  0.0290\n",
      "     14        \u001b[36m0.3589\u001b[0m       0.8019        \u001b[35m0.5296\u001b[0m  0.0288\n",
      "     15        \u001b[36m0.3387\u001b[0m       0.7925        \u001b[35m0.5137\u001b[0m  0.0288\n",
      "     16        \u001b[36m0.3194\u001b[0m       0.8019        \u001b[35m0.5023\u001b[0m  0.0293\n",
      "     17        \u001b[36m0.3010\u001b[0m       0.8019        \u001b[35m0.4885\u001b[0m  0.0292\n",
      "     18        \u001b[36m0.2832\u001b[0m       \u001b[32m0.8113\u001b[0m        \u001b[35m0.4765\u001b[0m  0.0292\n",
      "     19        \u001b[36m0.2661\u001b[0m       0.8113        \u001b[35m0.4668\u001b[0m  0.0290\n",
      "     20        \u001b[36m0.2498\u001b[0m       0.8113        \u001b[35m0.4574\u001b[0m  0.0288\n",
      "     21        \u001b[36m0.2336\u001b[0m       \u001b[32m0.8396\u001b[0m        \u001b[35m0.4476\u001b[0m  0.0293\n",
      "     22        \u001b[36m0.2187\u001b[0m       0.8113        \u001b[35m0.4407\u001b[0m  0.0291\n",
      "     23        \u001b[36m0.2052\u001b[0m       0.8208        \u001b[35m0.4293\u001b[0m  0.0294\n",
      "     24        \u001b[36m0.1928\u001b[0m       0.8113        \u001b[35m0.4217\u001b[0m  0.0289\n",
      "     25        \u001b[36m0.1817\u001b[0m       0.8019        \u001b[35m0.4144\u001b[0m  0.0284\n",
      "     26        \u001b[36m0.1711\u001b[0m       0.8208        \u001b[35m0.4025\u001b[0m  0.0290\n",
      "     27        \u001b[36m0.1620\u001b[0m       0.8113        \u001b[35m0.3954\u001b[0m  0.0289\n",
      "     28        \u001b[36m0.1534\u001b[0m       0.8208        \u001b[35m0.3887\u001b[0m  0.0286\n",
      "     29        \u001b[36m0.1461\u001b[0m       0.7925        \u001b[35m0.3872\u001b[0m  0.0292\n",
      "     30        \u001b[36m0.1373\u001b[0m       0.8019        \u001b[35m0.3771\u001b[0m  0.0297\n",
      "     31        \u001b[36m0.1304\u001b[0m       0.8113        \u001b[35m0.3736\u001b[0m  0.0291\n",
      "     32        \u001b[36m0.1234\u001b[0m       0.8019        \u001b[35m0.3711\u001b[0m  0.0299\n",
      "     33        \u001b[36m0.1171\u001b[0m       0.8019        0.3711  0.0293\n",
      "     34        \u001b[36m0.1121\u001b[0m       0.8019        \u001b[35m0.3684\u001b[0m  0.0303\n",
      "     35        \u001b[36m0.1070\u001b[0m       0.8113        \u001b[35m0.3545\u001b[0m  0.0303\n",
      "     36        \u001b[36m0.1016\u001b[0m       0.8113        \u001b[35m0.3514\u001b[0m  0.0291\n",
      "     37        \u001b[36m0.0966\u001b[0m       0.8113        0.3517  0.0305\n",
      "     38        \u001b[36m0.0926\u001b[0m       0.8302        \u001b[35m0.3375\u001b[0m  0.0293\n",
      "     39        \u001b[36m0.0905\u001b[0m       0.8113        0.3478  0.0296\n",
      "     40        \u001b[36m0.0863\u001b[0m       0.8113        0.3507  0.0297\n",
      "     41        \u001b[36m0.0820\u001b[0m       0.8208        \u001b[35m0.3305\u001b[0m  0.0295\n",
      "     42        \u001b[36m0.0799\u001b[0m       0.8208        0.3335  0.0290\n",
      "     43        \u001b[36m0.0750\u001b[0m       0.8208        0.3383  0.0291\n",
      "     44        \u001b[36m0.0719\u001b[0m       0.8208        0.3353  0.0286\n",
      "     45        \u001b[36m0.0709\u001b[0m       \u001b[32m0.8491\u001b[0m        \u001b[35m0.2824\u001b[0m  0.0295\n",
      "     46        \u001b[36m0.0696\u001b[0m       0.8208        0.3232  0.0283\n",
      "     47        \u001b[36m0.0641\u001b[0m       \u001b[32m0.8585\u001b[0m        \u001b[35m0.2748\u001b[0m  0.0328\n",
      "     48        0.0654       0.8113        0.3408  0.0282\n",
      "     49        \u001b[36m0.0620\u001b[0m       \u001b[32m0.9057\u001b[0m        \u001b[35m0.2392\u001b[0m  0.0293\n",
      "     50        \u001b[36m0.0599\u001b[0m       0.8113        0.3367  0.0292\n",
      "0.3749816401468788 0.6895238095238095\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7870\u001b[0m       \u001b[32m0.6498\u001b[0m        \u001b[35m0.6868\u001b[0m  0.0594\n",
      "      2        \u001b[36m0.7490\u001b[0m       \u001b[32m0.7051\u001b[0m        \u001b[35m0.6693\u001b[0m  0.0602\n",
      "      3        \u001b[36m0.7024\u001b[0m       \u001b[32m0.7097\u001b[0m        \u001b[35m0.6456\u001b[0m  0.0582\n",
      "      4        \u001b[36m0.6406\u001b[0m       \u001b[32m0.7189\u001b[0m        \u001b[35m0.6249\u001b[0m  0.0593\n",
      "      5        \u001b[36m0.5673\u001b[0m       \u001b[32m0.7419\u001b[0m        \u001b[35m0.6065\u001b[0m  0.0577\n",
      "      6        \u001b[36m0.4942\u001b[0m       \u001b[32m0.7926\u001b[0m        \u001b[35m0.5892\u001b[0m  0.0575\n",
      "      7        \u001b[36m0.4336\u001b[0m       \u001b[32m0.8249\u001b[0m        \u001b[35m0.5824\u001b[0m  0.0583\n",
      "      8        \u001b[36m0.3887\u001b[0m       \u001b[32m0.8525\u001b[0m        \u001b[35m0.5796\u001b[0m  0.0581\n",
      "      9        \u001b[36m0.3547\u001b[0m       \u001b[32m0.8710\u001b[0m        0.5803  0.0578\n",
      "     10        \u001b[36m0.3264\u001b[0m       0.6682        0.5858  0.0577\n",
      "     11        \u001b[36m0.3022\u001b[0m       0.5438        0.5995  0.0571\n",
      "     12        \u001b[36m0.2812\u001b[0m       0.5023        0.6202  0.0586\n",
      "     13        \u001b[36m0.2631\u001b[0m       0.4793        0.6412  0.0591\n",
      "     14        \u001b[36m0.2479\u001b[0m       0.4793        0.6506  0.0579\n",
      "     15        \u001b[36m0.2349\u001b[0m       0.4793        0.6568  0.0591\n",
      "     16        \u001b[36m0.2231\u001b[0m       0.4793        0.6669  0.0590\n",
      "     17        \u001b[36m0.2118\u001b[0m       0.4793        0.6652  0.0582\n",
      "     18        \u001b[36m0.2014\u001b[0m       0.4793        0.6736  0.0599\n",
      "     19        \u001b[36m0.1915\u001b[0m       0.4793        0.6717  0.0591\n",
      "     20        \u001b[36m0.1820\u001b[0m       0.4793        0.6685  0.0596\n",
      "     21        \u001b[36m0.1732\u001b[0m       0.4793        0.6674  0.0580\n",
      "     22        \u001b[36m0.1657\u001b[0m       0.4793        0.6778  0.0631\n",
      "     23        \u001b[36m0.1601\u001b[0m       0.4793        0.6760  0.0587\n",
      "     24        \u001b[36m0.1533\u001b[0m       0.4793        0.6652  0.0584\n",
      "     25        \u001b[36m0.1464\u001b[0m       0.4747        0.6801  0.0586\n",
      "     26        \u001b[36m0.1414\u001b[0m       0.4747        0.6814  0.0598\n",
      "     27        \u001b[36m0.1375\u001b[0m       0.4839        0.6719  0.0584\n",
      "     28        \u001b[36m0.1335\u001b[0m       0.4747        0.6989  0.0586\n",
      "     29        \u001b[36m0.1288\u001b[0m       0.4747        0.6939  0.0577\n",
      "     30        0.1292       0.4747        0.7004  0.0575\n",
      "     31        \u001b[36m0.1245\u001b[0m       0.4700        0.7079  0.0577\n",
      "     32        \u001b[36m0.1191\u001b[0m       0.4700        0.7204  0.0592\n",
      "     33        \u001b[36m0.1170\u001b[0m       0.4654        0.7215  0.0575\n",
      "     34        \u001b[36m0.1133\u001b[0m       0.4700        0.7266  0.0583\n",
      "     35        \u001b[36m0.1132\u001b[0m       0.4839        0.7240  0.0577\n",
      "     36        \u001b[36m0.1085\u001b[0m       0.4700        0.7497  0.0580\n",
      "     37        \u001b[36m0.1069\u001b[0m       0.4700        0.7528  0.0582\n",
      "     38        \u001b[36m0.1037\u001b[0m       0.4793        0.7518  0.0576\n",
      "     39        \u001b[36m0.1007\u001b[0m       0.4700        0.7730  0.0676\n",
      "     40        \u001b[36m0.0981\u001b[0m       0.4700        0.7843  0.0564\n",
      "     41        \u001b[36m0.0955\u001b[0m       0.4700        0.7955  0.0580\n",
      "     42        \u001b[36m0.0953\u001b[0m       0.4700        0.8125  0.0590\n",
      "     43        \u001b[36m0.0913\u001b[0m       0.4700        0.8071  0.0587\n",
      "     44        \u001b[36m0.0876\u001b[0m       0.4654        0.8181  0.0594\n",
      "     45        \u001b[36m0.0860\u001b[0m       0.4654        0.8252  0.0594\n",
      "     46        \u001b[36m0.0838\u001b[0m       0.4700        0.8330  0.0584\n",
      "     47        \u001b[36m0.0806\u001b[0m       0.4700        0.8539  0.0591\n",
      "     48        \u001b[36m0.0778\u001b[0m       0.4747        0.8509  0.0579\n",
      "     49        \u001b[36m0.0763\u001b[0m       0.4747        0.8554  0.0591\n",
      "     50        \u001b[36m0.0717\u001b[0m       0.4700        0.8922  0.0584\n",
      "0.5162099125364431 0.9028571428571428\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.5890\u001b[0m       \u001b[32m0.8354\u001b[0m        \u001b[35m0.6280\u001b[0m  0.0856\n",
      "      2        \u001b[36m0.5109\u001b[0m       \u001b[32m0.8384\u001b[0m        \u001b[35m0.6210\u001b[0m  0.0857\n",
      "      3        \u001b[36m0.4329\u001b[0m       \u001b[32m0.8720\u001b[0m        \u001b[35m0.6148\u001b[0m  0.0869\n",
      "      4        \u001b[36m0.3662\u001b[0m       \u001b[32m0.8811\u001b[0m        \u001b[35m0.6052\u001b[0m  0.0866\n",
      "      5        \u001b[36m0.3081\u001b[0m       0.8232        \u001b[35m0.5966\u001b[0m  0.0857\n",
      "      6        \u001b[36m0.2635\u001b[0m       0.7226        \u001b[35m0.5913\u001b[0m  0.0857\n",
      "      7        \u001b[36m0.2320\u001b[0m       0.6341        0.5925  0.0891\n",
      "      8        \u001b[36m0.2088\u001b[0m       0.6311        0.5953  0.0854\n",
      "      9        \u001b[36m0.1879\u001b[0m       0.6159        0.5954  0.0856\n",
      "     10        \u001b[36m0.1714\u001b[0m       0.6128        0.6008  0.0837\n",
      "     11        \u001b[36m0.1577\u001b[0m       0.5915        0.6126  0.0866\n",
      "     12        \u001b[36m0.1462\u001b[0m       0.5854        0.6182  0.0865\n",
      "     13        \u001b[36m0.1370\u001b[0m       0.5610        0.6379  0.0877\n",
      "     14        \u001b[36m0.1279\u001b[0m       0.5457        0.6547  0.0867\n",
      "     15        \u001b[36m0.1214\u001b[0m       0.5427        0.6603  0.0857\n",
      "     16        \u001b[36m0.1146\u001b[0m       0.5305        0.6850  0.0860\n",
      "     17        \u001b[36m0.1078\u001b[0m       0.5122        0.7182  0.0880\n",
      "     18        \u001b[36m0.1033\u001b[0m       0.4878        0.7348  0.0863\n",
      "     19        \u001b[36m0.0988\u001b[0m       0.4543        0.7570  0.0869\n",
      "     20        \u001b[36m0.0950\u001b[0m       0.4146        0.7826  0.0859\n",
      "     21        \u001b[36m0.0918\u001b[0m       0.3720        0.8099  0.0837\n",
      "     22        \u001b[36m0.0896\u001b[0m       0.4329        0.7938  0.0867\n",
      "     23        \u001b[36m0.0892\u001b[0m       0.3628        0.8382  0.0865\n",
      "     24        \u001b[36m0.0874\u001b[0m       0.3567        0.8507  0.0888\n",
      "     25        \u001b[36m0.0802\u001b[0m       0.3445        0.8780  0.0858\n",
      "     26        \u001b[36m0.0789\u001b[0m       0.3323        0.8948  0.0857\n",
      "     27        \u001b[36m0.0746\u001b[0m       0.2927        0.9409  0.0877\n",
      "     28        0.0749       0.2988        0.9494  0.0864\n",
      "     29        \u001b[36m0.0710\u001b[0m       0.2713        0.9901  0.0874\n",
      "     30        \u001b[36m0.0702\u001b[0m       0.2591        1.0198  0.0866\n",
      "     31        \u001b[36m0.0699\u001b[0m       0.2683        1.0235  0.0871\n",
      "     32        \u001b[36m0.0677\u001b[0m       0.2774        1.0283  0.0863\n",
      "     33        \u001b[36m0.0646\u001b[0m       0.2652        1.0731  0.0856\n",
      "     34        \u001b[36m0.0628\u001b[0m       0.2744        1.0740  0.0845\n",
      "     35        \u001b[36m0.0608\u001b[0m       0.2713        1.0894  0.0867\n",
      "     36        \u001b[36m0.0592\u001b[0m       0.2713        1.1142  0.0853\n",
      "     37        \u001b[36m0.0563\u001b[0m       0.2896        1.1275  0.0861\n",
      "     38        0.0571       0.2713        1.1681  0.0864\n",
      "     39        \u001b[36m0.0542\u001b[0m       0.2744        1.1562  0.0900\n",
      "     40        \u001b[36m0.0523\u001b[0m       0.2896        1.1458  0.0857\n",
      "     41        \u001b[36m0.0513\u001b[0m       0.2744        1.1864  0.0869\n",
      "     42        0.0528       0.2866        1.1596  0.0867\n",
      "     43        \u001b[36m0.0498\u001b[0m       0.2744        1.1881  0.0866\n",
      "     44        \u001b[36m0.0470\u001b[0m       0.2774        1.2047  0.0875\n",
      "     45        \u001b[36m0.0456\u001b[0m       0.2927        1.1866  0.0855\n",
      "     46        0.0479       0.3018        1.1995  0.0864\n",
      "     47        \u001b[36m0.0429\u001b[0m       0.2927        1.2261  0.0861\n",
      "     48        0.0451       0.2988        1.2181  0.0845\n",
      "     49        0.0437       0.2896        1.2796  0.0859\n",
      "     50        \u001b[36m0.0410\u001b[0m       0.2927        1.2852  0.0873\n",
      "0.8477532434057908 0.780952380952381\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7540\u001b[0m       \u001b[32m0.8314\u001b[0m        \u001b[35m0.6637\u001b[0m  0.1162\n",
      "      2        \u001b[36m0.6460\u001b[0m       \u001b[32m0.8360\u001b[0m        \u001b[35m0.6320\u001b[0m  0.1152\n",
      "      3        \u001b[36m0.5381\u001b[0m       0.8337        \u001b[35m0.5943\u001b[0m  0.1150\n",
      "      4        \u001b[36m0.4469\u001b[0m       0.8337        \u001b[35m0.5547\u001b[0m  0.1179\n",
      "      5        \u001b[36m0.3727\u001b[0m       0.8292        \u001b[35m0.5197\u001b[0m  0.1165\n",
      "      6        \u001b[36m0.3185\u001b[0m       0.8064        \u001b[35m0.5084\u001b[0m  0.1151\n",
      "      7        \u001b[36m0.2789\u001b[0m       \u001b[32m0.8542\u001b[0m        \u001b[35m0.4850\u001b[0m  0.1154\n",
      "      8        \u001b[36m0.2487\u001b[0m       \u001b[32m0.8633\u001b[0m        \u001b[35m0.4671\u001b[0m  0.1142\n",
      "      9        \u001b[36m0.2269\u001b[0m       0.8519        \u001b[35m0.4649\u001b[0m  0.1157\n",
      "     10        \u001b[36m0.2064\u001b[0m       0.8337        0.4658  0.1163\n",
      "     11        \u001b[36m0.1910\u001b[0m       0.8109        0.4725  0.1143\n",
      "     12        \u001b[36m0.1842\u001b[0m       0.7585        0.4867  0.1175\n",
      "     13        \u001b[36m0.1690\u001b[0m       0.7927        0.4856  0.1165\n",
      "     14        \u001b[36m0.1627\u001b[0m       0.7062        0.5042  0.1128\n",
      "     15        \u001b[36m0.1544\u001b[0m       0.7062        0.5099  0.1146\n",
      "     16        \u001b[36m0.1474\u001b[0m       0.7062        0.5185  0.1145\n",
      "     17        \u001b[36m0.1406\u001b[0m       0.6925        0.5264  0.1154\n",
      "     18        \u001b[36m0.1398\u001b[0m       0.6948        0.5353  0.1159\n",
      "     19        \u001b[36m0.1300\u001b[0m       0.6925        0.5383  0.1174\n",
      "     20        \u001b[36m0.1278\u001b[0m       0.6925        0.5444  0.1142\n",
      "     21        \u001b[36m0.1226\u001b[0m       0.6925        0.5458  0.1148\n",
      "     22        0.1245       0.6925        0.5548  0.1150\n",
      "     23        \u001b[36m0.1149\u001b[0m       0.6925        0.5582  0.1137\n",
      "     24        \u001b[36m0.1140\u001b[0m       0.6925        0.5680  0.1150\n",
      "     25        \u001b[36m0.1110\u001b[0m       0.6856        0.5713  0.1154\n",
      "     26        \u001b[36m0.1060\u001b[0m       0.6902        0.5798  0.1159\n",
      "     27        0.1075       0.6925        0.5791  0.1149\n",
      "     28        \u001b[36m0.1039\u001b[0m       0.6697        0.5968  0.1167\n",
      "     29        \u001b[36m0.1014\u001b[0m       0.6606        0.6121  0.1166\n",
      "     30        0.1031       0.6606        0.6183  0.1151\n",
      "     31        \u001b[36m0.0979\u001b[0m       0.6811        0.6126  0.1164\n",
      "     32        \u001b[36m0.0938\u001b[0m       0.6606        0.6362  0.1184\n",
      "     33        0.0976       0.6697        0.6246  0.1156\n",
      "     34        \u001b[36m0.0904\u001b[0m       0.6560        0.6522  0.1160\n",
      "     35        0.0936       0.6515        0.6616  0.1163\n",
      "     36        0.0909       0.6651        0.6417  0.1155\n",
      "     37        0.0939       0.6560        0.6627  0.1160\n",
      "     38        \u001b[36m0.0899\u001b[0m       0.6720        0.6412  0.1164\n",
      "     39        \u001b[36m0.0842\u001b[0m       0.6651        0.6591  0.1147\n",
      "     40        \u001b[36m0.0839\u001b[0m       0.6697        0.6488  0.1149\n",
      "     41        \u001b[36m0.0817\u001b[0m       0.6515        0.6830  0.1153\n",
      "     42        \u001b[36m0.0803\u001b[0m       0.6629        0.6722  0.1167\n",
      "     43        \u001b[36m0.0792\u001b[0m       0.6651        0.6703  0.1165\n",
      "     44        0.0803       0.6743        0.6543  0.1151\n",
      "     45        \u001b[36m0.0780\u001b[0m       0.6560        0.6866  0.1245\n",
      "     46        \u001b[36m0.0751\u001b[0m       0.6629        0.6770  0.1159\n",
      "     47        0.0762       0.6560        0.7017  0.1157\n",
      "     48        \u001b[36m0.0743\u001b[0m       0.6788        0.6756  0.1137\n",
      "     49        0.0752       0.6788        0.6691  0.1164\n",
      "     50        \u001b[36m0.0743\u001b[0m       0.6765        0.6745  0.1159\n",
      "0.8992322456813819 0.8171428571428572\n"
     ]
    }
   ],
   "source": [
    "AUC_ROCs = dict()\n",
    "ACCs = dict()\n",
    "model_name = \"LSTM\"\n",
    "print(model_name)\n",
    "AUC_ROCs[model_name] = 0\n",
    "ACCs[model_name] = 0\n",
    "for train_index, test_index in tscv.split(X_train): # Rolling cross-validation happens inside this loop.\n",
    "    X_train_fold, X_validation_fold = X_train.iloc[train_index[:-lag_of_y], X_train.columns != \"USRECD\"], \\\n",
    "        X_train.iloc[test_index[:-lag_of_y], X_train.columns != \"USRECD\"]\n",
    "    y_train_fold, y_validation_fold = y_train.iloc[train_index[lag_of_y:], y_train.columns == \"USRECD\"], \\\n",
    "        y_train.iloc[test_index[lag_of_y:], y_train.columns == \"USRECD\"]\n",
    "\n",
    "    scalers = dict()\n",
    "    for feature in features:\n",
    "        scalers[feature] = StandardScaler()\n",
    "        scalers[feature].fit(X_train_fold[[feature]])\n",
    "        X_train_fold[feature] = scalers[feature].transform(X_train_fold[[feature]])\n",
    "        X_validation_fold[feature] = scalers[feature].transform(X_validation_fold[[feature]])\n",
    "\n",
    "    X_train_fold, y_train_fold = split_sequences(X_train_fold.to_numpy(), y_train_fold.to_numpy(), n_steps=10)\n",
    "    X_train_fold = X_train_fold.astype(np.float32)\n",
    "    y_train_fold = y_train_fold.astype(np.float32)\n",
    "    X_validation_fold, y_validation_fold = split_sequences(X_validation_fold.to_numpy(), y_validation_fold.to_numpy(), n_steps=10)\n",
    "    X_validation_fold = X_validation_fold.astype(np.float32)\n",
    "    y_validation_fold = y_validation_fold.astype(np.float32)\n",
    "    model = get_model()\n",
    "    model.fit(X_train_fold, y_train_fold)\n",
    "    positive_probs = [p[1] for p in model.predict_proba(X_validation_fold)]\n",
    "    AUC_ROC = metrics.roc_auc_score(y_validation_fold, positive_probs)\n",
    "    AUC_ROCs[model_name] += AUC_ROC\n",
    "    predictions = model.predict(X_validation_fold)\n",
    "    ACC = accuracy_score(y_validation_fold, predictions)\n",
    "    ACCs[model_name] += ACC\n",
    "    print(AUC_ROC, ACC)\n",
    "\n",
    "AUC_ROCs[model_name] /= splits\n",
    "ACCs[model_name] /= splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM\n",
      "AUC ROC: 0.6595442604426236\n",
      "accuracy: 0.7976190476190476\n"
     ]
    }
   ],
   "source": [
    "print(model_name)\n",
    "print(f\"AUC ROC: {AUC_ROCs[model_name]}\")\n",
    "print(f\"accuracy: {ACCs[model_name]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
